# üéì Ejemplo de Uso Completo: Pipeline MLOps con DVC

Este documento muestra un ejemplo completo de c√≥mo usar el pipeline de notebooks con versionado DVC.

---

## üìã Escenario

Eres un miembro del Equipo 36 y vas a trabajar en el proyecto desde cero. Seguir√°s estos pasos:

1. Configurar el ambiente
2. Ejecutar los 3 notebooks
3. Versionar los datos en cada paso
4. Compartir tu trabajo con el equipo

---

## üõ†Ô∏è Paso 0: Configuraci√≥n Inicial (solo una vez)

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/equipo36mlops.git
cd equipo36mlops
```

### 2. Instalar dependencias

```bash
# Crear ambiente virtual (opcional pero recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### 3. Configurar AWS (para DVC)

```bash
# Ejecutar el script de configuraci√≥n
bash setup_aws_credentials.sh

# Cuando te pida, ingresa:
# - AWS Access Key ID: [tu-access-key]
# - AWS Secret Access Key: [tu-secret-key]
# - Region: us-east-2
```

### 4. Verificar configuraci√≥n de DVC

```bash
# Ver configuraci√≥n de DVC
cat .dvc/config

# Deber√≠a mostrar:
# [core]
#     remote = s3remote
# ['remote "s3remote"']
#     url = s3://mlops-team36-bucket/equipo36mlops
#     region = us-east-2
```

### 5. Descargar datos existentes (si ya existen)

```bash
# Si el equipo ya ha versionado datos
dvc pull

# Verificar que los datos se descargaron
ls -lh data/raw/
```

---

## üìä Paso 1: Ejecutar Notebook 1 - EDA y Limpieza

### 1.1. Antes de empezar

```bash
# Aseg√∫rate de tener la √∫ltima versi√≥n del c√≥digo
git pull

# Aseg√∫rate de tener los datos raw
dvc pull
```

### 1.2. Abrir y ejecutar el notebook

```bash
# Abrir Jupyter
jupyter notebook notebooks/1_EDA_and_Cleaning.ipynb

# O si usas JupyterLab
jupyter lab notebooks/1_EDA_and_Cleaning.ipynb
```

**Ejecuta todas las celdas del notebook.** Al final, el notebook:
- Lee: `data/raw/student_entry_performance.csv`
- Guarda: `data/processed/student_performance.csv`
- Muestra instrucciones de versionado

### 1.3. Versionar el resultado

```bash
# Volver a la terminal
cd /Users/hectoralvarez/Documents/GitHub/equipo36mlops

# Ejecutar el comando que el notebook te mostr√≥
bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1-cleaned 'Dataset after EDA cleaning'
```

**Salida esperada**:

```
======================================================================
   üì¶ DVC Data Versioning Helper - Equipo 36 MLOps
======================================================================

‚ÑπÔ∏è  Archivo a versionar: data/processed/student_performance.csv
‚ÑπÔ∏è  Tag: data-v1.1-cleaned
‚ÑπÔ∏è  Mensaje: Dataset after EDA cleaning

----------------------------------------------------------------------
‚ÑπÔ∏è  PASO 1: Verificando estado del archivo...
----------------------------------------------------------------------
‚ÑπÔ∏è  Agregando archivo nuevo a DVC...
‚úÖ Archivo agregado a DVC

----------------------------------------------------------------------
‚ÑπÔ∏è  PASO 2: Agregando metadatos DVC a Git...
----------------------------------------------------------------------
‚úÖ Metadatos agregados a Git

----------------------------------------------------------------------
‚ÑπÔ∏è  PASO 3: Creando commit...
----------------------------------------------------------------------
[main abc1234] feat: version data - Dataset after EDA cleaning
 2 files changed, 8 insertions(+)
 create mode 100644 data/processed/student_performance.csv.dvc

----------------------------------------------------------------------
‚ÑπÔ∏è  PASO 4: Creando tag Git...
----------------------------------------------------------------------
‚úÖ Tag creado: data-v1.1-cleaned

----------------------------------------------------------------------
‚ÑπÔ∏è  PASO 5: Subiendo datos a DVC remote (S3)...
----------------------------------------------------------------------
1 file pushed
‚úÖ Datos subidos a S3

----------------------------------------------------------------------
‚ÑπÔ∏è  PASO 6: Subiendo metadatos y tags a Git remote...
----------------------------------------------------------------------
‚úÖ Push completado

======================================================================
‚úÖ VERSIONADO COMPLETADO
======================================================================

‚ÑπÔ∏è  Resumen:
  üìÅ Archivo:     data/processed/student_performance.csv
  üè∑Ô∏è  Tag:         data-v1.1-cleaned
  üìù Descripci√≥n: Dataset after EDA cleaning

‚ÑπÔ∏è  Para recuperar esta versi√≥n en el futuro:
  git checkout data-v1.1-cleaned
  dvc checkout

‚úÖ ¬°Listo! Tus datos est√°n versionados correctamente.
======================================================================
```

### 1.4. Verificar que todo funcion√≥

```bash
# Ver que el archivo .dvc se cre√≥
ls -l data/processed/

# Deber√≠as ver:
# student_performance.csv
# student_performance.csv.dvc

# Ver el contenido del archivo .dvc
cat data/processed/student_performance.csv.dvc

# Ver que el tag se cre√≥
git tag -l

# Deber√≠as ver:
# data-v1.1-cleaned
```

---

## üîß Paso 2: Ejecutar Notebook 2 - Feature Engineering

### 2.1. Antes de empezar

```bash
# Aseg√∫rate de tener la versi√≥n limpia de los datos
dvc pull

# Verificar que el archivo existe
ls -lh data/processed/student_performance.csv
```

### 2.2. Abrir y ejecutar el notebook

```bash
jupyter notebook notebooks/2_Data_Processing.ipynb
```

**Ejecuta todas las celdas del notebook.** Al final, el notebook:
- Lee: `data/processed/student_performance.csv`
- Aplica: Feature selection, encoding, PCA
- Guarda: `data/processed/student_performance_features.csv`
- Guarda: `onehot_encoder.pkl` (encoder para uso posterior)

### 2.3. Versionar el resultado

```bash
# Ejecutar el comando que el notebook te mostr√≥
bash add_to_dvc.sh data/processed/student_performance_features.csv data-v1.2-features 'Features with PCA ready for modeling'
```

### 2.4. Versionar tambi√©n el encoder (opcional pero recomendado)

```bash
# Mover el encoder al directorio de modelos
mkdir -p models/encoders
mv onehot_encoder.pkl models/encoders/

# Versionarlo con DVC
bash add_to_dvc.sh models/encoders/onehot_encoder.pkl encoders-v1.0 'OneHot encoder for nominal variables'
```

---

## ü§ñ Paso 3: Ejecutar Notebook 3 - Entrenamiento de Modelos

### 3.1. Antes de empezar

```bash
# Aseg√∫rate de tener las features
dvc pull

# Verificar que el archivo existe
ls -lh data/processed/student_performance_features.csv
```

### 3.2. Abrir y ejecutar el notebook

```bash
jupyter notebook notebooks/3_Model_Training_and_Registering.ipynb
```

**Ejecuta todas las celdas del notebook.** El notebook:
- Lee: `data/processed/student_performance_features.csv`
- Entrena: LightGBM, XGBoost, CatBoost
- Registra: Experimentos en MLflow (directorio `data/mlflow/`)
- Calcula: M√©tricas RMSE y QWK

### 3.3. Ver experimentos en MLflow (opcional)

Si ejecutaste la celda que levanta el servidor de MLflow:

```bash
# Abrir en el navegador
# http://127.0.0.1:8080

# Ah√≠ podr√°s ver:
# - Todos los experimentos
# - M√©tricas de cada modelo
# - Par√°metros usados
# - Comparaci√≥n entre modelos
```

### 3.4. Versionar los modelos

```bash
# Ejecutar el comando que el notebook te mostr√≥
bash add_to_dvc.sh data/mlflow models-v1.0-baseline 'Baseline models: LightGBM, XGBoost, CatBoost'
```

---

## üéâ Paso 4: Verificar el Pipeline Completo

### 4.1. Ver todas las versiones creadas

```bash
# Listar todos los tags
git tag -l

# Deber√≠as ver:
# data-v1.0-raw            (ya exist√≠a)
# data-v1.1-cleaned        (creado en Paso 1)
# data-v1.2-features       (creado en Paso 2)
# encoders-v1.0            (creado en Paso 2 opcional)
# models-v1.0-baseline     (creado en Paso 3)
```

### 4.2. Ver el historial de commits

```bash
git log --oneline --all --graph --decorate

# Deber√≠as ver algo como:
# * def5678 (tag: models-v1.0-baseline) feat: version models - baseline models trained
# * abc1234 (tag: data-v1.2-features) feat: version data - features engineered
# * xyz9876 (tag: data-v1.1-cleaned) feat: version data - dataset after EDA
```

### 4.3. Ver qu√© archivos est√°n en S3

```bash
# Ver archivos en el bucket S3
aws s3 ls s3://mlops-team36-bucket/equipo36mlops/ --recursive

# O usando DVC
dvc list -R . --dvc-only
```

---

## üë• Paso 5: Compartir con el Equipo

Tu trabajo ya est√° en Git y S3. Ahora tus compa√±eros pueden descargarlo.

### 5.1. Avisar al equipo

Env√≠a un mensaje a tu equipo:

```
¬°Hola equipo! üëã

Acabo de completar el pipeline hasta el entrenamiento de modelos baseline.

Versiones creadas:
‚úÖ data-v1.1-cleaned: Dataset despu√©s de EDA
‚úÖ data-v1.2-features: Features con PCA
‚úÖ models-v1.0-baseline: Modelos LightGBM, XGBoost, CatBoost

Para obtener todo:
1. git pull
2. dvc pull

Para ver los experimentos de MLflow:
cd /Users/hectoralvarez/Documents/GitHub/equipo36mlops
mlflow ui --backend-store-uri file:./data/mlflow
# Abrir http://localhost:5000

¬°Pueden empezar a trabajar con estos modelos! üöÄ
```

---

## üîÑ Paso 6: Recuperar una Versi√≥n Anterior (Ejemplo)

Supongamos que quieres volver a la versi√≥n de datos limpios (sin features).

### 6.1. Cambiar a esa versi√≥n

```bash
# Cambiar a la versi√≥n de datos limpios
git checkout data-v1.1-cleaned

# Descargar los datos de esa versi√≥n
dvc checkout

# Ver el archivo
head data/processed/student_performance.csv

# ‚úÖ Ahora tienes los datos tal como estaban despu√©s del EDA
```

### 6.2. Experimentar con esa versi√≥n

```bash
# Puedes abrir un notebook y experimentar
jupyter notebook notebooks/2_Data_Processing.ipynb

# Modificar par√°metros, probar diferentes transformaciones, etc.
```

### 6.3. Volver al estado actual

```bash
# Volver a la rama principal
git checkout main

# Descargar los datos m√°s recientes
dvc checkout

# ‚úÖ Ahora tienes la √∫ltima versi√≥n de todo
```

---

## üîç Paso 7: Comparar Versiones (Ejemplo Avanzado)

### 7.1. Comparar dos versiones de datos

```bash
# Ver diferencias en metadatos (tama√±o, hash)
dvc diff data-v1.1-cleaned data-v1.2-features

# Salida esperada:
# Path                                      Metric    Old       New     Change
# data/processed/student_performance.csv    size      150KB     -       deleted
# data/processed/student_performance_features.csv  size    -    25KB    added
```

### 7.2. Extraer ambas versiones para comparaci√≥n manual

```bash
# Crear directorio temporal
mkdir -p /tmp/comparison

# Extraer versi√≥n 1.1
git checkout data-v1.1-cleaned
dvc checkout
cp data/processed/student_performance.csv /tmp/comparison/v1.1.csv

# Extraer versi√≥n 1.2
git checkout data-v1.2-features
dvc checkout
cp data/processed/student_performance_features.csv /tmp/comparison/v1.2.csv

# Volver a la versi√≥n actual
git checkout main
dvc checkout

# Comparar con Python
python3 << EOF
import pandas as pd

df_v11 = pd.read_csv('/tmp/comparison/v1.1.csv')
df_v12 = pd.read_csv('/tmp/comparison/v1.2.csv')

print(f"v1.1 - Shape: {df_v11.shape}")
print(f"v1.2 - Shape: {df_v12.shape}")
print(f"\nv1.1 columns: {df_v11.columns.tolist()}")
print(f"\nv1.2 columns: {df_v12.columns.tolist()}")
EOF
```

---

## üö® Troubleshooting: Problemas Comunes

### Problema 1: "dvc pull" no descarga nada

**Causa**: Puede que no haya archivos nuevos para descargar, o que ya los tengas.

**Soluci√≥n**:
```bash
# Ver estado
dvc status

# Si dice "Data and pipelines are up to date", est√° todo bien

# Si quieres forzar la descarga
dvc pull --force
```

---

### Problema 2: "No remote storage is configured"

**Causa**: DVC no sabe d√≥nde est√° tu S3.

**Soluci√≥n**:
```bash
# Ver configuraci√≥n actual
dvc remote list

# Si no aparece nada, configurar:
dvc remote add -d s3remote s3://mlops-team36-bucket/equipo36mlops
dvc remote modify s3remote region us-east-2
```

---

### Problema 3: "Unable to find credentials"

**Causa**: AWS CLI no tiene credenciales configuradas.

**Soluci√≥n**:
```bash
# Opci√≥n 1: Ejecutar el script
bash setup_aws_credentials.sh

# Opci√≥n 2: Configurar manualmente
aws configure
```

---

### Problema 4: El notebook no encuentra el archivo de datos

**Causa**: No has descargado los datos con `dvc pull`.

**Soluci√≥n**:
```bash
# Descargar datos
dvc pull

# Verificar que el archivo existe
ls -lh data/processed/student_performance.csv
```

---

### Problema 5: "Tag already exists"

**Causa**: Est√°s intentando crear un tag que ya existe.

**Soluci√≥n**:
```bash
# Opci√≥n 1: Usar un tag diferente con versi√≥n patch
bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1.1-cleaned 'Updated cleaning'

# Opci√≥n 2: Borrar y recrear (usar con precauci√≥n)
git tag -d data-v1.1-cleaned
bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1-cleaned 'Dataset after EDA cleaning'
```

---

## üìö Recursos de Ayuda

- **Gu√≠a completa**: `docs/DVC_WORKFLOW.md`
- **Comandos r√°pidos**: `DVC_COMMANDS.md`
- **Gu√≠a de notebooks**: `notebooks/README_DVC.md`
- **Documentaci√≥n DVC**: https://dvc.org/doc

---

## ‚úÖ Checklist Final

Despu√©s de completar este ejemplo, deber√≠as tener:

- [x] Ambiente configurado con AWS y DVC
- [x] Los 3 notebooks ejecutados
- [x] 4-5 versiones de datos creadas y subidas a S3
- [x] Modelos entrenados y versionados
- [x] Todo el trabajo compartido con el equipo via Git+DVC
- [x] Capacidad de recuperar cualquier versi√≥n anterior

---

**¬°Felicidades! Has completado el flujo completo de MLOps con versionado de datos. üéâ**

---

**Equipo 36 MLOps** | Octubre 2025

