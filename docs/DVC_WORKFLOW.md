# üì¶ Gu√≠a Completa de Versionado de Datos con DVC
## Equipo 36 - MLOps

---

## üéØ Objetivo

Este documento describe el flujo completo de versionado de datos y modelos en el proyecto `equipo36mlops` utilizando **DVC (Data Version Control)** con almacenamiento remoto en **AWS S3**.

---

## üìö Tabla de Contenidos

1. [Conceptos B√°sicos](#conceptos-b√°sicos)
2. [Configuraci√≥n Inicial](#configuraci√≥n-inicial)
3. [Flujo de Trabajo del Pipeline](#flujo-de-trabajo-del-pipeline)
4. [Comandos Esenciales](#comandos-esenciales)
5. [Mejores Pr√°cticas](#mejores-pr√°cticas)
6. [Resoluci√≥n de Problemas](#resoluci√≥n-de-problemas)

---

## üß† Conceptos B√°sicos

### ¬øQu√© es DVC?

**DVC (Data Version Control)** es una herramienta de c√≥digo abierto para versionado de datos y modelos de Machine Learning. Funciona de manera similar a Git, pero est√° dise√±ada espec√≠ficamente para archivos grandes y binarios.

### ¬øPor qu√© usar DVC?

‚úÖ **Reproducibilidad**: Puedes recuperar cualquier versi√≥n de tus datos o modelos  
‚úÖ **Colaboraci√≥n**: Tu equipo puede trabajar con los mismos datos versionados  
‚úÖ **Almacenamiento eficiente**: Los archivos grandes se almacenan en S3, no en Git  
‚úÖ **Trazabilidad**: Cada cambio en los datos queda registrado  

### Arquitectura del Proyecto

```
equipo36mlops/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Datos originales sin procesar
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ student_entry_performance.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ student_entry_performance.csv.dvc  ‚Üê Archivo DVC (va a Git)
‚îÇ   ‚îú‚îÄ‚îÄ processed/                    # Datos procesados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ student_performance.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ student_performance.csv.dvc
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ student_performance_features.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ student_performance_features.csv.dvc
‚îÇ   ‚îî‚îÄ‚îÄ mlflow/                       # Experimentos y modelos
‚îÇ       ‚îî‚îÄ‚îÄ mlflow.dvc
‚îú‚îÄ‚îÄ notebooks/                        # Notebooks del pipeline
‚îÇ   ‚îú‚îÄ‚îÄ 1_EDA_and_Cleaning.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 2_Data_Processing.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 3_Model_Training_and_Registering.ipynb
‚îú‚îÄ‚îÄ add_to_dvc.sh                     # Script helper para versionado
‚îî‚îÄ‚îÄ .dvc/
    ‚îî‚îÄ‚îÄ config                        # Configuraci√≥n DVC (S3)
```

### Archivos `.dvc`

Los archivos `.dvc` son **metadatos** que DVC crea para trackear tus archivos grandes:

```yaml
outs:
- md5: 3c4fda9b9e4e9f1c8d5e6a7b8c9d0e1f
  size: 98765
  path: student_performance.csv
```

- **md5**: Hash √∫nico del archivo para detectar cambios
- **size**: Tama√±o del archivo en bytes
- **path**: Ruta relativa del archivo

üîë **Importante**: Los archivos `.dvc` son peque√±os y se guardan en Git, mientras que los archivos grandes se suben a S3.

---

## ‚öôÔ∏è Configuraci√≥n Inicial

### 1. Verificar configuraci√≥n de DVC

```bash
# Ver configuraci√≥n actual
cat .dvc/config

# Deber√≠as ver algo como:
# [core]
#     remote = s3remote
# ['remote "s3remote"']
#     url = s3://mlops-team36-bucket/equipo36mlops
#     region = us-east-2
```

### 2. Verificar credenciales AWS

```bash
# Verificar que las credenciales est√©n configuradas
aws sts get-caller-identity

# Si no est√°n configuradas, ejecuta:
bash setup_aws_credentials.sh
```

### 3. Hacer el script ejecutable

```bash
# Dar permisos de ejecuci√≥n al script helper
chmod +x add_to_dvc.sh
```

---

## üîÑ Flujo de Trabajo del Pipeline

El proyecto tiene **3 notebooks** que se ejecutan secuencialmente, cada uno con su propia versi√≥n de datos:

### üìä Pipeline Completo

```mermaid
graph LR
    A[data-v0.1-raw] --> B[1_EDA_and_Cleaning.ipynb]
    B --> C[data-v1.1-cleaned]
    C --> D[2_Data_Processing.ipynb]
    D --> E[data-v1.2-features]
    E --> F[3_Model_Training.ipynb]
    F --> G[models-v1.0-baseline]
```

### üîπ Paso 1: EDA y Limpieza de Datos

**Notebook**: `1_EDA_and_Cleaning.ipynb`

**Input**: `data/raw/student_entry_performance.csv` (ya versionado: `data-v1.0-raw`)

**Output**: `data/processed/student_performance.csv`

**Cambios aplicados**:
- Normalizaci√≥n de texto (may√∫sculas, trim)
- Manejo de valores nulos
- Eliminaci√≥n de columna `mixed_type_col`
- Imputaci√≥n de valores faltantes

**Versionar el resultado**:

```bash
# Ejecutar al terminar el notebook 1
cd /Users/hectoralvarez/Documents/GitHub/equipo36mlops
bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1-cleaned 'Dataset after EDA cleaning'
```

---

### üîπ Paso 2: Feature Engineering

**Notebook**: `2_Data_Processing.ipynb`

**Input**: `data/processed/student_performance.csv` (versi√≥n: `data-v1.1-cleaned`)

**Output**: `data/processed/student_performance_features.csv`

**Cambios aplicados**:
- An√°lisis de frecuencia de variables
- Chi-cuadrada y Cramer's V para variables nominales
- Correlaci√≥n de Spearman para variables ordinales
- One-Hot Encoding de variables nominales
- PCA para reducci√≥n de dimensionalidad (95% de varianza)

**Versionar el resultado**:

```bash
# Ejecutar al terminar el notebook 2
bash add_to_dvc.sh data/processed/student_performance_features.csv data-v1.2-features 'Features with PCA ready for modeling'
```

---

### üîπ Paso 3: Entrenamiento de Modelos

**Notebook**: `3_Model_Training_and_Registering.ipynb`

**Input**: `data/processed/student_performance_features.csv` (versi√≥n: `data-v1.2-features`)

**Output**: `data/mlflow/` (directorio con experimentos MLflow)

**Modelos entrenados**:
- LightGBM
- XGBoost
- CatBoost

**M√©tricas registradas**:
- RMSE (Root Mean Squared Error)
- QWK (Quadratic Weighted Kappa)

**Versionar los modelos**:

```bash
# Ejecutar al terminar el notebook 3
bash add_to_dvc.sh data/mlflow models-v1.0-baseline 'Baseline models: LightGBM, XGBoost, CatBoost'
```

---

## üõ†Ô∏è Comandos Esenciales

### Versionar un archivo nuevo

```bash
# Opci√≥n 1: Usar el script helper (recomendado)
bash add_to_dvc.sh <archivo> <tag> <mensaje>

# Ejemplo:
bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1-cleaned 'Dataset after EDA cleaning'
```

```bash
# Opci√≥n 2: Comandos manuales
dvc add <archivo>
git add <archivo>.dvc .gitignore
git commit -m "feat: version data - <descripci√≥n>"
git tag -a "<tag>" -m "<mensaje>"
dvc push
git push origin <branch> --tags
```

### Actualizar un archivo ya versionado

```bash
# Cuando modificas un archivo que ya est√° trackeado por DVC
dvc add data/processed/student_performance.csv
git add data/processed/student_performance.csv.dvc
git commit -m "feat: update data - improved cleaning"
git tag -a "data-v1.1.1-cleaned" -m "Updated cleaning logic"
dvc push
git push origin <branch> --tags
```

### Descargar datos versionados

```bash
# Descargar todos los archivos DVC del commit actual
dvc pull

# Descargar un archivo espec√≠fico
dvc pull data/processed/student_performance.csv.dvc
```

### Recuperar una versi√≥n espec√≠fica

```bash
# Cambiar a una versi√≥n espec√≠fica por tag
git checkout data-v1.1-cleaned
dvc checkout

# Ver el archivo en esa versi√≥n
head data/processed/student_performance.csv

# Volver al estado m√°s reciente
git checkout main  # o tu rama principal
dvc checkout
```

### Ver el estado de DVC

```bash
# Ver qu√© archivos est√°n trackeados por DVC
dvc status

# Ver el historial de cambios en un archivo
git log --oneline -- data/processed/student_performance.csv.dvc

# Ver tags disponibles
git tag -l
```

### Comparar versiones

```bash
# Ver diferencias entre versiones (metadatos)
git diff data-v1.1-cleaned data-v1.2-features -- data/processed/student_performance.csv.dvc

# Comparar tama√±os de archivos
dvc diff data-v1.1-cleaned data-v1.2-features
```

---

## üåü Mejores Pr√°cticas

### 1. Nomenclatura de Tags

Usa una convenci√≥n consistente para los tags:

```
<tipo>-v<major>.<minor>.<patch>-<descripci√≥n>

Ejemplos:
- data-v1.0-raw           # Datos originales
- data-v1.1-cleaned       # Primera versi√≥n procesada
- data-v1.2-features      # Features engineered
- models-v1.0-baseline    # Modelos baseline
- models-v2.0-optimized   # Modelos optimizados
```

### 2. Mensajes de Commit

Sigue el formato Conventional Commits:

```bash
feat: version data - nueva transformaci√≥n aplicada
fix: correct data - corregir error en imputaci√≥n
docs: update DVC workflow documentation
```

### 3. Sincronizaci√≥n del Equipo

```bash
# Al inicio de tu sesi√≥n de trabajo
git pull
dvc pull

# Al terminar tu trabajo
bash add_to_dvc.sh <archivo> <tag> <mensaje>
# El script hace autom√°ticamente: dvc push y git push
```

### 4. No versionar archivos temporales

Aseg√∫rate de que `.gitignore` incluya:

```gitignore
# Archivos de datos grandes (manejados por DVC)
/data/raw/*.csv
/data/processed/*.csv
/data/mlflow/

# Archivos temporales
*.tmp
*.swp
__pycache__/
.ipynb_checkpoints/
```

### 5. Documentar cambios en los datos

Cada vez que versiones datos, documenta:
- ¬øQu√© cambi√≥?
- ¬øPor qu√© cambi√≥?
- ¬øQu√© impacto tiene en el modelo?

```bash
# Bueno ‚úÖ
bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1-cleaned 'Removed outliers and imputed missing values in Class_X_Percentage'

# Malo ‚ùå
bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1 'update'
```

---

## üîß Resoluci√≥n de Problemas

### Problema: "No remote storage is configured"

**Soluci√≥n**:
```bash
# Verificar configuraci√≥n
cat .dvc/config

# Si no est√° configurado, ejecutar:
bash setup_dvc.sh data/raw/student_entry_performance.csv
```

---

### Problema: "Unable to find credentials"

**Soluci√≥n**:
```bash
# Configurar credenciales AWS
bash setup_aws_credentials.sh

# O manualmente:
aws configure
# Introduce: Access Key ID, Secret Access Key, Region (us-east-2)
```

---

### Problema: "File is already tracked by DVC"

**Causa**: Intentas hacer `dvc add` en un archivo ya versionado.

**Soluci√≥n**:
```bash
# Para actualizar, simplemente vuelve a hacer dvc add
dvc add data/processed/student_performance.csv
git add data/processed/student_performance.csv.dvc
git commit -m "feat: update data - nueva versi√≥n"
```

---

### Problema: "Modified dependencies detected"

**Causa**: El archivo cambi√≥ pero no has actualizado DVC.

**Soluci√≥n**:
```bash
# Actualizar DVC
dvc add <archivo_modificado>
git add <archivo_modificado>.dvc
git commit -m "feat: update data"
dvc push
```

---

### Problema: Tag ya existe

**Soluci√≥n 1 (actualizar tag local)**:
```bash
# Borrar tag local y recrearlo
git tag -d data-v1.1-cleaned
git tag -a data-v1.1-cleaned -m "Nueva descripci√≥n"
```

**Soluci√≥n 2 (usar nuevo tag)**:
```bash
# Crear un nuevo tag con versi√≥n patch
bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1.1-cleaned 'Actualizaci√≥n con mejoras'
```

---

### Problema: No puedo hacer push a S3

**Verificar permisos**:
```bash
# Verificar que tienes acceso al bucket
aws s3 ls s3://mlops-team36-bucket/

# Si no tienes permisos, contacta al administrador del proyecto
```

---

## üìã Checklist de Trabajo

### Antes de empezar a trabajar:

- [ ] `git pull` - Sincronizar c√≥digo
- [ ] `dvc pull` - Sincronizar datos
- [ ] Verificar que est√°s en la rama correcta
- [ ] Verificar que tienes las credenciales AWS configuradas

### Al terminar un notebook:

- [ ] Guardar el archivo de datos procesado
- [ ] Ejecutar `bash add_to_dvc.sh <archivo> <tag> <mensaje>`
- [ ] Verificar que el push a S3 fue exitoso
- [ ] Verificar que el push a Git fue exitoso
- [ ] Documentar los cambios en el commit

### Antes de compartir con el equipo:

- [ ] Verificar que todos los tags est√°n creados
- [ ] Verificar que `dvc push` complet√≥ sin errores
- [ ] Verificar que `git push --tags` complet√≥ sin errores
- [ ] Avisar al equipo sobre la nueva versi√≥n disponible

---

## üéì Recursos Adicionales

- [Documentaci√≥n oficial de DVC](https://dvc.org/doc)
- [DVC con S3](https://dvc.org/doc/user-guide/data-management/remote-storage/amazon-s3)
- [Best practices for MLOps](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

---

## üë• Contacto y Soporte

Para preguntas sobre este flujo de trabajo, contacta a:

- **Equipo**: Equipo 36 MLOps
- **Proyecto**: equipo36mlops
- **Bucket S3**: `s3://mlops-team36-bucket/equipo36mlops`

---

**√öltima actualizaci√≥n**: Octubre 2025  
**Versi√≥n del documento**: 1.0

