# ğŸ“¦ Mejores PrÃ¡cticas: Versionado de Artefactos ML con DVC

## ğŸ¯ Â¿QuÃ© son los Artefactos ML?

Los **artefactos ML** son archivos binarios generados durante el proceso de Machine Learning:

- ğŸ”§ **Transformadores**: Encoders, scalers, PCA, etc. (`.pkl`, `.joblib`)
- ğŸ¤– **Modelos entrenados**: XGBoost, LightGBM, redes neuronales (`.pkl`, `.h5`, `.bin`)
- ğŸ“Š **Objetos de preprocesamiento**: Vocabularios, tokenizers, etc.

---

## âš ï¸ Regla de Oro

| Tipo de Archivo | Manejado por | RazÃ³n |
|-----------------|--------------|-------|
| **Archivos `.pkl`, `.joblib`, `.h5`** | âœ… **DVC** | Son binarios y pueden ser grandes |
| **Archivos `.dvc`** (metadatos) | âœ… **Git** | Son pequeÃ±os y contienen referencias |
| **CÃ³digo Python, notebooks** | âœ… **Git** | Son archivos de texto |
| **Archivos CSV grandes** | âœ… **DVC** | Datos grandes |

---

## ğŸ—ï¸ Estructura Recomendada

```
proyecto/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ encoders/              # ğŸ”§ Transformadores de encoding
â”‚   â”‚   â”œâ”€â”€ onehot_encoder.pkl
â”‚   â”‚   â”œâ”€â”€ label_encoder.pkl
â”‚   â”‚   â””â”€â”€ ordinal_encoder.pkl
â”‚   â”‚
â”‚   â”œâ”€â”€ scalers/               # ğŸ“ Normalizadores y escaladores
â”‚   â”‚   â”œâ”€â”€ standard_scaler.pkl
â”‚   â”‚   â””â”€â”€ minmax_scaler.pkl
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessors/         # ğŸ”„ Transformadores dimensionales
â”‚   â”‚   â”œâ”€â”€ pca_model.pkl
â”‚   â”‚   â”œâ”€â”€ feature_selector.pkl
â”‚   â”‚   â””â”€â”€ imputer.pkl
â”‚   â”‚
â”‚   â””â”€â”€ trained_models/        # ğŸ¤– Modelos entrenados
â”‚       â”œâ”€â”€ xgboost_v1.pkl
â”‚       â”œâ”€â”€ lightgbm_v1.pkl
â”‚       â””â”€â”€ nn_model.h5
â”‚
â”œâ”€â”€ models.dvc                 # Archivo DVC que trackea todo /models/
â””â”€â”€ .gitignore                 # Ignora *.pkl, *.joblib, *.h5, etc.
```

---

## ğŸ“ Nomenclatura de Artefactos

### Nombres Descriptivos

âœ… **Bueno**:
```
onehot_encoder_v1.0.pkl
pca_95_variance.pkl
xgboost_baseline_v1.pkl
lightgbm_optimized_v2.pkl
```

âŒ **Malo**:
```
encoder.pkl
model.pkl
final.pkl
final_final_v3.pkl
```

### Incluir Metadata en el Nombre

```python
# Ejemplo de guardado con metadata
encoder_name = f"onehot_encoder_v{VERSION}_{datetime.now().strftime('%Y%m%d')}.pkl"
joblib.dump(encoder, f"../models/encoders/{encoder_name}")
```

---

## ğŸ”„ Flujo de Trabajo: Crear y Versionar

### Paso 1: Entrenar/Crear el Artefacto

```python
from sklearn.preprocessing import OneHotEncoder
import joblib
import os

# Crear encoder
encoder = OneHotEncoder(sparse_output=False, drop='first')
encoder.fit(df[categorical_cols])

# Guardar en directorio apropiado
os.makedirs('../models/encoders', exist_ok=True)
encoder_path = '../models/encoders/onehot_encoder.pkl'
joblib.dump(encoder, encoder_path)

print(f"âœ… Encoder guardado: {encoder_path}")
```

### Paso 2: Versionar con DVC

#### OpciÃ³n A: Versionar directorio completo (RECOMENDADO)

```bash
# Versionar todo el directorio models/
bash add_to_dvc.sh models artifacts-v1.0 'Initial preprocessing artifacts'
```

**Ventajas**:
- âœ… Un solo `.dvc` file maneja todo
- âœ… Todos los artefactos se sincronizan juntos
- âœ… MÃ¡s simple de mantener

#### OpciÃ³n B: Versionar archivos individuales

```bash
# Versionar encoder especÃ­fico
bash add_to_dvc.sh models/encoders/onehot_encoder.pkl encoders-v1.0 'OneHot encoder for categorical features'

# Versionar PCA
bash add_to_dvc.sh models/preprocessors/pca_model.pkl pca-v1.0 'PCA with 95% variance explained'
```

**Ventajas**:
- âœ… Control granular de versiones
- âœ… Puedes recuperar artefactos individuales

**Desventajas**:
- âš ï¸ MÃ¡s archivos `.dvc` para mantener
- âš ï¸ Riesgo de desincronizaciÃ³n

---

## ğŸ·ï¸ ConvenciÃ³n de Tags

### Para Artefactos de Preprocesamiento

```
artifacts-v<major>.<minor>-<description>

Ejemplos:
- artifacts-v1.0            # Primera versiÃ³n
- artifacts-v1.1-updated    # ActualizaciÃ³n menor
- artifacts-v2.0-redesign   # RediseÃ±o completo
```

### Para Modelos Entrenados

```
models-v<major>.<minor>-<type>

Ejemplos:
- models-v1.0-baseline      # Modelos baseline
- models-v1.1-tuned         # Con hyperparameter tuning
- models-v2.0-ensemble      # Modelos ensemble
```

---

## ğŸ“Š Ejemplo Completo: Notebook 2_Data_Processing

### En el Notebook

```python
import os
import joblib
from sklearn.preprocessing import OneHotEncoder
from sklearn.decomposition import PCA

# === 1. Entrenar encoder ===
encoder = OneHotEncoder(sparse_output=False, drop='first')
encoder.fit(df[nominal_variables])

# === 2. Guardar encoder ===
os.makedirs('../models/encoders', exist_ok=True)
encoder_path = '../models/encoders/onehot_encoder.pkl'
joblib.dump(encoder, encoder_path)
print(f"âœ… Encoder guardado: {encoder_path}")

# === 3. Entrenar PCA ===
pca = PCA(n_components=0.95)
pca.fit(X_features)

# === 4. Guardar PCA ===
os.makedirs('../models/preprocessors', exist_ok=True)
pca_path = '../models/preprocessors/pca_model.pkl'
joblib.dump(pca, pca_path)
print(f"âœ… PCA guardado: {pca_path}")

# === 5. Mostrar instrucciones de versionado ===
print("\n" + "="*70)
print("ğŸ“¦ SIGUIENTE PASO: Versionar con DVC")
print("="*70)
print(f"bash add_to_dvc.sh models artifacts-v1.0 'Preprocessing artifacts: encoder and PCA'")
```

### En la Terminal

```bash
# Ejecutar despuÃ©s de terminar el notebook
cd /Users/hectoralvarez/Documents/GitHub/equipo36mlops

# Versionar todos los artefactos
bash add_to_dvc.sh models artifacts-v1.0 'Preprocessing artifacts: encoder and PCA'

# Verificar
git status
dvc status

# Ver estructura
tree models/
```

**Resultado esperado**:

```
models/
â”œâ”€â”€ encoders/
â”‚   â””â”€â”€ onehot_encoder.pkl     # Ignorado por Git, manejado por DVC
â”œâ”€â”€ preprocessors/
â”‚   â””â”€â”€ pca_model.pkl          # Ignorado por Git, manejado por DVC
â””â”€â”€ models.dvc                 # En Git (metadatos)
```

---

## ğŸ” Cargar Artefactos Versionados

### Desde otro compaÃ±ero del equipo

```bash
# 1. Clonar el repo (si no lo tienes)
git clone <repo-url>
cd equipo36mlops

# 2. Configurar AWS (si no lo has hecho)
bash setup_aws_credentials.sh

# 3. Descargar artefactos
dvc pull

# 4. Verificar que existen
ls -lh models/encoders/
ls -lh models/preprocessors/
```

### En Python

```python
import joblib

# Cargar encoder
encoder = joblib.load('../models/encoders/onehot_encoder.pkl')

# Cargar PCA
pca = joblib.load('../models/preprocessors/pca_model.pkl')

# Usar para transformar nuevos datos
X_encoded = encoder.transform(X_new_categorical)
X_pca = pca.transform(X_new_features)
```

---

## ğŸ”„ Actualizar Artefactos Existentes

### Escenario: Cambiaste el preprocesamiento

```python
# En el notebook, modificaste el encoder
encoder_new = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')
encoder_new.fit(df[nominal_variables])

# Sobrescribir archivo
joblib.dump(encoder_new, '../models/encoders/onehot_encoder.pkl')
```

### Versionar la actualizaciÃ³n

```bash
# DVC detectarÃ¡ el cambio automÃ¡ticamente
bash add_to_dvc.sh models artifacts-v1.1-updated 'Updated encoder with handle_unknown=ignore'
```

**Lo que pasa internamente**:

1. DVC calcula el nuevo MD5 del archivo
2. Sube la nueva versiÃ³n a S3
3. Actualiza `models.dvc` con el nuevo hash
4. Git guarda el cambio en `models.dvc`
5. Se crea un nuevo tag `artifacts-v1.1-updated`

---

## ğŸ“‹ Mejores PrÃ¡cticas

### âœ… DO (Hacer)

1. **Versionar TODO artefacto que se use en producciÃ³n**
   ```bash
   dvc add models/encoders/
   dvc add models/trained_models/
   ```

2. **Usar nombres descriptivos**
   ```python
   joblib.dump(model, 'xgboost_baseline_rmse_0.85.pkl')
   ```

3. **Documentar dependencias de versiones**
   ```python
   # Este encoder fue entrenado con data-v1.1-cleaned
   encoder_metadata = {
       'data_version': 'data-v1.1-cleaned',
       'trained_date': '2025-10-13',
       'features': categorical_cols
   }
   joblib.dump({'encoder': encoder, 'metadata': encoder_metadata}, encoder_path)
   ```

4. **Versionar encoder Y datos juntos (tags relacionados)**
   ```bash
   # Primero los datos
   bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1-cleaned 'Cleaned data'
   
   # Luego los artefactos entrenados CON esos datos
   bash add_to_dvc.sh models/encoders artifacts-v1.1-cleaned 'Artifacts trained with data-v1.1-cleaned'
   ```

### âŒ DON'T (No hacer)

1. **NO versionar con Git**
   ```bash
   # âŒ MALO
   git add models/encoders/onehot_encoder.pkl
   
   # âœ… BUENO
   dvc add models/encoders/onehot_encoder.pkl
   ```

2. **NO guardar en directorios temporales o notebooks/**
   ```python
   # âŒ MALO
   joblib.dump(encoder, 'encoder.pkl')  # En notebook/
   
   # âœ… BUENO
   joblib.dump(encoder, '../models/encoders/onehot_encoder.pkl')
   ```

3. **NO usar nombres genÃ©ricos**
   ```python
   # âŒ MALO
   joblib.dump(model, 'model.pkl')
   joblib.dump(model, 'final.pkl')
   
   # âœ… BUENO
   joblib.dump(model, 'xgboost_v1_baseline.pkl')
   ```

4. **NO olvidar hacer dvc push**
   ```bash
   dvc add models/
   git add models.dvc
   git commit -m "Add models"
   # âŒ Si olvidas esto, tus compaÃ±eros no tendrÃ¡n los archivos!
   dvc push  # âœ… CRÃTICO
   ```

---

## ğŸ”§ Comandos Ãštiles

### Ver quÃ© artefactos estÃ¡n versionados

```bash
# Listar archivos trackeados por DVC
dvc list . -R --dvc-only

# Ver estado de DVC
dvc status

# Ver quÃ© archivos estÃ¡n en S3
aws s3 ls s3://mlops-team36-bucket/equipo36mlops/ --recursive | grep models
```

### Recuperar versiÃ³n especÃ­fica de artefactos

```bash
# Cambiar a una versiÃ³n anterior
git checkout artifacts-v1.0
dvc checkout

# Ver los artefactos de esa versiÃ³n
ls -lh models/

# Volver a la versiÃ³n actual
git checkout main
dvc checkout
```

### Comparar tamaÃ±os de artefactos entre versiones

```bash
# Ver diferencias entre versiones
dvc diff artifacts-v1.0 artifacts-v1.1-updated

# Ver tamaÃ±o de un artefacto especÃ­fico
ls -lh models/encoders/onehot_encoder.pkl
```

---

## ğŸ“Š Ejemplo Real: Pipeline Completo

### Notebook 1: EDA y Limpieza

```python
# Guarda: data/processed/student_performance.csv
df_clean.to_csv('../data/processed/student_performance.csv', index=False)
```

**Versionar**:
```bash
bash add_to_dvc.sh data/processed/student_performance.csv data-v1.1-cleaned 'Dataset after EDA'
```

---

### Notebook 2: Feature Engineering

```python
# Entrena y guarda: encoder, PCA
joblib.dump(encoder, '../models/encoders/onehot_encoder.pkl')
joblib.dump(pca, '../models/preprocessors/pca_model.pkl')

# Guarda: data/processed/student_performance_features.csv
df_features.to_csv('../data/processed/student_performance_features.csv', index=False)
```

**Versionar**:
```bash
# Features
bash add_to_dvc.sh data/processed/student_performance_features.csv data-v1.2-features 'Features with PCA'

# Artefactos (entrenados con data-v1.1-cleaned)
bash add_to_dvc.sh models artifacts-v1.2-features 'Preprocessing artifacts trained with data-v1.1-cleaned'
```

---

### Notebook 3: Model Training

```python
# Entrena y guarda modelos con MLflow (se guarda en data/mlflow/)
# MLflow guarda automÃ¡ticamente los modelos como artifacts

# Puedes tambiÃ©n guardar modelos individuales
joblib.dump(best_model, '../models/trained_models/xgboost_best.pkl')
```

**Versionar**:
```bash
# MLflow completo
bash add_to_dvc.sh data/mlflow models-v1.0-baseline 'Baseline models: LightGBM, XGBoost, CatBoost'

# O modelo especÃ­fico
bash add_to_dvc.sh models/trained_models trained-models-v1.0 'Best trained models'
```

---

## ğŸ¯ Resumen Ejecutivo

| Paso | AcciÃ³n | Comando |
|------|--------|---------|
| 1 | Entrenar artefacto | `encoder.fit(X)` |
| 2 | Guardar en `models/` | `joblib.dump(encoder, '../models/encoders/encoder.pkl')` |
| 3 | Versionar con DVC | `bash add_to_dvc.sh models artifacts-v1.0 'Description'` |
| 4 | Compartir con equipo | *AutomÃ¡tico con el script* |
| 5 | Descargar en otro equipo | `dvc pull` |
| 6 | Cargar artefacto | `encoder = joblib.load('models/encoders/encoder.pkl')` |

---

## ğŸ†˜ Troubleshooting

### Problema: "File too large for Git"

**Causa**: Intentaste hacer `git add` en un archivo `.pkl`

**SoluciÃ³n**:
```bash
# Remover del staging de Git
git rm --cached models/encoders/onehot_encoder.pkl

# Versionar correctamente con DVC
bash add_to_dvc.sh models/encoders/onehot_encoder.pkl encoders-v1.0 'Encoder'
```

---

### Problema: "FileNotFoundError: No such file 'encoder.pkl'"

**Causa**: No descargaste los artefactos con `dvc pull`

**SoluciÃ³n**:
```bash
dvc pull
```

---

### Problema: Artefacto corrupto despuÃ©s de `dvc pull`

**SoluciÃ³n**:
```bash
# Limpiar cache y re-descargar
dvc pull --force
```

---

## ğŸ“š Recursos Adicionales

- [DVC Documentation: Managing Large Files](https://dvc.org/doc/start/data-management)
- [Joblib Documentation](https://joblib.readthedocs.io/)
- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)

---

**Ãšltima actualizaciÃ³n**: Octubre 2025  
**Equipo 36 MLOps** | Tec de Monterrey

