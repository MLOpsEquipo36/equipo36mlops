# Vista general

En la carpeta "pipeline", podremos encontrar los scripts de python que definen la l√≥gica de ejecuci√≥n de un Pipeline de extremo a extremo para predecir el desempe√±o estudiantil, con etapas claras y reproducibles: limpieza de datos, ingenier√≠a de caracter√≠sticas, entrenamiento de modelos y tracking/registro de experimentos con MLflow.

Los principales objetivos del desarrollo del pipeline son:

* Modularidad: cada etapa (limpieza, features, entrenamiento) est√° implementada como componentes desacoplados e independientes hasta cierto punto.

* Reproducibilidad: semillas aleatorias fijas, configuraciones centralizadas en YAML y logging consistente.

* Observabilidad: m√©tricas, par√°metros y artefactos son enviados a MLflow para auditor√≠a y comparaci√≥n de experimentos.

* Practicidad: soporta entrenar m√∫ltiples modelos (LightGBM, XGBoost, CatBoost), evaluaci√≥n con m√©tricas relevantes (RMSE, QWK) y registro autom√°tico del mejor modelo en el MLflow Model Registry.

# Archivos y carpetas clave

* config/training.yaml ‚Äî Archivo YAML que centraliza rutas, par√°metros de entrenamiento, y toggles del pipeline.

* src/pipeline/run_training.py ‚Äî Script que ejecuta: limpieza ‚Üí creaci√≥n de features ‚Üí entrenamiento ‚Üí registro.

* src/models/train_model.py ‚Äî Implementa ModelTrainer que:
    * Carga datos procesados,
    * Separa train/test,
    * Entrena LightGBM, XGBoost y CatBoost (cada uno con su m√©todo),
    * Calcula RMSE y QWK,
    * Loggea par√°metros, m√©tricas y modelos en MLflow,
    * Registra el mejor modelo en el Model Registry.

* data/mlflow/ ‚Äî Store local de MLflow (puede cambiarse por un backend remoto).

# Configuraci√≥n

Toda la configuraci√≥n del pipeline se centraliza en un √∫nico archivo YAML ubicado en:

```bash
config/training.yaml
```
Esto permite modificar rutas, par√°metros del modelo, m√©tricas y opciones de ejecuci√≥n sin tocar el c√≥digo fuente.

A continuaci√≥n se muestra un ejemplo de configuraci√≥n t√≠pica:

```yaml
paths:
  raw_data: data/raw/student_performance.csv
  interim_data: data/interim/student_performance.csv
  processed_data: data/processed/student_performance_features.csv
  mlflow_dir: data/mlflow

pipeline:
  cleaning:
    force: false                   # Si es true, fuerza la limpieza aunque ya exista un archivo limpio
  features:
    variance_threshold: 0.01        # Umbral para eliminar variables con baja varianza
    force: false
  training:
    metric: qwk                     # M√©trica principal (qwk o rmse)

model_training:
  target_column: Performance         # Columna objetivo a predecir
  test_size: 0.2                     # Proporci√≥n del conjunto de test
  random_state: 13                   # Semilla fija para reproducibilidad
  model: all                         # Opciones: 'lightgbm', 'xgboost', 'catboost' o 'all'
  experiment_name: mlflow-student-performance-experiment
  hyperparameters: {}                # Par√°metros del modelo (vac√≠o usa valores por defecto)
```

üí° Notas:

* Los directorios indicados en paths se crean autom√°ticamente si no existen.

* Puedes cambiar el modelo a entrenar con model: "lightgbm" o cualquier otro soportado.

* force: true permite regenerar datos o features aunque los archivos ya existan.

* Todas las m√©tricas, artefactos y par√°metros se registran autom√°ticamente en MLflow.

# Uso

El pipeline est√° dise√±ado para ejecutarse con un solo comando, ejecutando todas las etapas: limpieza ‚Üí features ‚Üí entrenamiento ‚Üí registro del modelo.

```bash
    python -m src.pipeline.run_training
```

Durante la ejecuci√≥n ver√°s mensajes informativos en consola y en logs (si est√°n habilitados), por ejemplo:

```bash
2025-11-02 11:01:18 - INFO - pipeline - üöÄ Iniciando pipeline de entrenamiento completo...
2025-11-02 11:01:18 - INFO - feature_engineering - üü° Features ya existen, se omite...
2025-11-02 11:01:19 - INFO - pipeline - Training and evaluating model: LightGBM
2025-11-02 11:01:21 - INFO - pipeline - Metrics - RMSE: 0.8376, QWK: 0.5564
2025-11-02 11:01:40 - INFO - pipeline - üèÜ Mejor modelo: LightGBM
2025-11-02 11:01:41 - INFO - pipeline - ‚úÖ Pipeline de entrenamiento finalizado con √©xito.
```

## Visualizar experimentos en MLflow

Para inspeccionar tus corridas de entrenamiento y comparar modelos visualmente:

```bash
mlflow ui --backend-store-uri file:data/mlflow
```

Luego abre en tu navegador:
üëâ http://localhost:5000

Desde la interfaz de MLflow podr√°s:

* Visualizar m√©tricas, par√°metros y artefactos.

* Descargar modelos entrenados.

* Promover versiones al MLflow Model Registry.