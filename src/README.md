# ğŸ“¦ MÃ³dulos Refactorizados - Estructura Cookiecutter

Este directorio contiene los scripts refactorizados de los notebooks, siguiendo buenas prÃ¡cticas de MLOps, principios de POO y estructura Cookiecutter.

## ğŸ“ Estructura

```
src/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ clean_data.py          # Refactorizado de 1_EDA_and_Cleaning.ipynb
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ build_features.py       # Refactorizado de 2_Data_Processing.ipynb
â””â”€â”€ models/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ train_model.py          # Refactorizado de 3_Model_Training_and_Registering.ipynb
```

## ğŸ¯ MÃ³dulos

### 1. `src/data/clean_data.py`

**Clase principal:** `DataCleaner`

Responsabilidades:
- Cargar datos raw
- NormalizaciÃ³n de texto (mayÃºsculas, trim)
- Manejo de valores nulos
- Limpieza de columnas no informativas
- Guardar datos limpios

**Uso:**

```python
from src.data import DataCleaner

cleaner = DataCleaner(
    input_path="data/raw/student_entry_performance.csv",
    output_path="data/processed/student_performance.csv"
)

# Ejecutar pipeline completo
cleaner.run_pipeline()
cleaner.save_cleaned_data()

# O usar mÃ©todos individuales
cleaner.load_data()
cleaner.normalize_case()
cleaner.trim_whitespace()
# ... mÃ¡s operaciones
```

**LÃ­nea de comandos:**

```bash
python -m src.data.clean_data --input data/raw/student_entry_performance.csv --output data/processed/student_performance.csv
```

### 2. `src/features/build_features.py`

**Clase principal:** `FeatureBuilder`

Responsabilidades:
- SelecciÃ³n de features (Chi-cuadrada, Cramer's V, Spearman)
- OneHot encoding para variables nominales
- AplicaciÃ³n de PCA para reducciÃ³n de dimensionalidad
- Guardar encoders y preprocessors
- Guardar features procesadas

**Uso:**

```python
from src.features import FeatureBuilder

builder = FeatureBuilder(
    input_path="data/processed/student_performance.csv",
    output_path="data/processed/student_performance_features.csv",
    encoder_dir="models/encoders",
    preprocessor_dir="models/preprocessors"
)

# Ejecutar pipeline completo
builder.run_pipeline(
    feature_selection=True,
    apply_encoding=True,
    apply_pca=True,
    variance_threshold=0.95
)

builder.save_features()
builder.save_artifacts()
```

**LÃ­nea de comandos:**

```bash
python -m src.features.build_features \
    --input data/processed/student_performance.csv \
    --output data/processed/student_performance_features.csv \
    --variance-threshold 0.95
```

### 3. `src/models/train_model.py`

**Clase principal:** `ModelTrainer`

Responsabilidades:
- Cargar features procesadas
- DivisiÃ³n train/test estratificada
- Entrenamiento de modelos (LightGBM, XGBoost, CatBoost)
- EvaluaciÃ³n y logging en MLflow
- ComparaciÃ³n de modelos

**Uso:**

```python
from src.models import ModelTrainer

trainer = ModelTrainer(
    input_path="data/processed/student_performance_features.csv",
    mlflow_dir="data/mlflow",
    experiment_name="mlflow-student-performance-experiment"
)

# Ejecutar pipeline completo
trainer.run_pipeline(
    target_column="Performance",
    test_size=0.2,
    random_state=13,
    train_all=True
)

# O entrenar modelos individuales
trainer.load_data()
trainer.split_data()
trainer.train_lightgbm()
trainer.train_xgboost()
trainer.train_catboost()

# Obtener el mejor modelo
best_model = trainer.get_best_model(metric="qwk")
```

**LÃ­nea de comandos:**

```bash
python -m src.models.train_model \
    --input data/processed/student_performance_features.csv \
    --model all \
    --target Performance
```

## ğŸ”„ Pipeline Completo

Para ejecutar el pipeline completo desde datos raw hasta modelos entrenados:

```bash
# 1. Limpiar datos
python -m src.data.clean_data \
    --input data/raw/student_entry_performance.csv \
    --output data/processed/student_performance.csv

# 2. Construir features
python -m src.features.build_features \
    --input data/processed/student_performance.csv \
    --output data/processed/student_performance_features.csv

# 3. Entrenar modelos
python -m src.models.train_model \
    --input data/processed/student_performance_features.csv \
    --model all
```

## ğŸ—ï¸ Principios de DiseÃ±o

### ProgramaciÃ³n Orientada a Objetos (POO)

- **EncapsulaciÃ³n**: Cada clase encapsula su propia lÃ³gica y estado
- **Responsabilidad Ãºnica**: Cada clase tiene una responsabilidad bien definida
- **ReutilizaciÃ³n**: MÃ©todos pÃºblicos permiten flexibilidad en el uso
- **Extensibilidad**: FÃ¡cil de extender con nuevos mÃ©todos o funcionalidades

### Modularidad

- Cada mÃ³dulo es independiente y puede ejecutarse por separado
- SeparaciÃ³n clara de concerns (datos, features, modelos)
- FÃ¡cil mantenimiento y testing

### Buenas PrÃ¡cticas MLOps

- **Logging estructurado**: Todas las operaciones estÃ¡n loggeadas
- **Reproducibilidad**: ParÃ¡metros configurables y random seeds
- **Versionado**: Compatible con DVC y MLflow
- **Pipeline automatizado**: MÃ©todos `run_pipeline()` para ejecuciÃ³n completa

## ğŸ“ Ejemplo de Uso Avanzado

```python
import logging
from src.data import DataCleaner
from src.features import FeatureBuilder
from src.models import ModelTrainer

# Configurar logging
logging.basicConfig(level=logging.INFO)

# 1. Limpieza de datos
cleaner = DataCleaner(
    input_path="data/raw/student_entry_performance.csv",
    output_path="data/processed/student_performance.csv",
    logger=logging.getLogger("data_cleaning")
)
cleaner.run_pipeline()
cleaner.save_cleaned_data()

# 2. Feature engineering
builder = FeatureBuilder(
    input_path="data/processed/student_performance.csv",
    output_path="data/processed/student_performance_features.csv",
    logger=logging.getLogger("feature_engineering")
)
builder.run_pipeline(variance_threshold=0.90)
builder.save_features()
builder.save_artifacts()

# 3. Entrenamiento
trainer = ModelTrainer(
    input_path="data/processed/student_performance_features.csv",
    logger=logging.getLogger("model_training")
)
metrics = trainer.run_pipeline()

# Comparar modelos
best_model = trainer.get_best_model(metric="qwk")
print(f"Mejor modelo: {best_model}")
print(f"MÃ©tricas: {trainer.model_metrics[best_model]}")
```

## âœ… Ventajas de la RefactorizaciÃ³n

1. **Mantenibilidad**: CÃ³digo organizado y fÃ¡cil de mantener
2. **ReutilizaciÃ³n**: Componentes reutilizables en otros proyectos
3. **Testing**: Estructura que facilita unit testing
4. **ColaboraciÃ³n**: CÃ³digo mÃ¡s legible para el equipo
5. **Escalabilidad**: FÃ¡cil agregar nuevas funcionalidades
6. **ProducciÃ³n**: Listo para integrar en pipelines de CI/CD

## ğŸ”§ Dependencias

Los scripts requieren las siguientes dependencias (deben estar en `pyproject.toml`):

- pandas
- numpy
- scikit-learn
- scipy
- lightgbm
- xgboost
- catboost
- mlflow
- joblib

AsegÃºrate de instalar todas las dependencias antes de ejecutar los scripts.

