{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60199491",
   "metadata": {},
   "source": [
    "# **Operaciones de aprendizaje automático**\n",
    "## **Maestría en Inteligencia Artificial Aplicada**\n",
    "### **Tecnológico de Monterrey**\n",
    "### **Equipo 36**\n",
    "**Fase 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46fb462",
   "metadata": {},
   "source": [
    "## **0. Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a6971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Setup ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d8de3b",
   "metadata": {},
   "source": [
    "## **1. Analisis de Requerimientos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c38193",
   "metadata": {},
   "source": [
    "En esta actividad se desarrollarán las primeras etapas de un proyecto de Machine Learning empleando el conjunto de datos titulado “Student Performance on an Entrance Examination”.\n",
    "Este dataset contiene información de candidatos que participaron en el examen de admisión médica (Common Entrance Examination - CEE) para ingresar a facultades de medicina en Assam (India), recopilada por el Prof. Jiten Hazarika, donde el problema principal a resolver consiste en identificar aquellos factores que influyen en el rendimiento académico de los estudiantes que presentan el examen de ingreso.\n",
    "\n",
    "El objetivo del proyecto es construir un modelo de clasificación que prediga el desempeño del candidato en función de variables como el género, tipo de coaching, antecedentes académicos y ocupación de los padres. Esto a partir del dataset \"student_entry_performance_modified.csv\".\n",
    "\n",
    "Esta fase está estructurada para abarcar desde la exploración, manipulación y preparación de los datos, hasta el diseño y evaluación de modelos de clasificación que permitan comprender los factores asociados al rendimiento en el examen de ingreso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e97b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../data/processed/student_entry_performance_modified.csv\")\n",
    "# Copia de trabajo\n",
    "df = df_raw.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a313204",
   "metadata": {},
   "source": [
    "A través del uso de técnicas de Machine Learning, este proyecto busca ofrecer un sistema de apoyo analítico que permita comprender cuales son las variables académicas y socioeconómicas que influyen en el desempeño estudiantil. La propuesta de valor radica en transformar los datos obtenidos del pasado en conocimiento útil para mejorar la planificación educativa y la preparación de futuros aspirantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5694e",
   "metadata": {},
   "source": [
    "## **2. Manipulación y preparación de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2b6e8",
   "metadata": {},
   "source": [
    "### 2.1 Mayus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfadcc3",
   "metadata": {},
   "source": [
    "Como primer acercamiento, en el df se aprecia que el elemento 3 en la columna de \"Class_XII_Percentage\" presenta el valor de \"eXCELLENT\", lo cual coincide con el valor de \"Excellent\" pero al no tener el mismo formato, no se reconoce igual, es por esto que la primera acción es pasarlo a mayúsculas para homogeneizar el df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_mayus = ['Performance', 'Gender', 'Caste', 'coaching', 'time',\n",
    "       'Class_ten_education', 'twelve_education', 'medium',\n",
    "       'Class_ X_Percentage', 'Class_XII_Percentage', 'Father_occupation',\n",
    "       'Mother_occupation', 'mixed_type_col']\n",
    "df[apply_mayus] = df[apply_mayus].apply(lambda x: x.str.upper())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2943076",
   "metadata": {},
   "source": [
    "### 2.2 Trim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e16058",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Performance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee3a6a",
   "metadata": {},
   "source": [
    "Tomando como ejemplo la columna de \"Performance\", se observa que hay valores que a la vista son iguales, pero se categorizan como otro tipo, posiblemente presente en las demás columnas, es por esto que se aplica la operación trim para solucionar esto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[apply_mayus] = df[apply_mayus].apply(lambda x: x.str.strip())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca119e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Performance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteos por clase\n",
    "target_col = 'Performance'\n",
    "target_counts = df[target_col].value_counts(dropna=False)\n",
    "target_ratio = (target_counts / len(df)).round(3)\n",
    "\n",
    "print(\"Distribución absoluta:\")\n",
    "display(target_counts)\n",
    "print(\"\\nDistribución relativa:\")\n",
    "display(target_ratio)\n",
    "\n",
    "# Histograma / barras por clase\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=target_col, data=df, order=target_counts.index)\n",
    "plt.title(\"Distribución de la variable objetivo\")\n",
    "plt.xlabel(\"Clase de rendimiento\")\n",
    "plt.ylabel(\"Conteo\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heurística de desbalance (ratio max/min)\n",
    "if target_counts.min() > 0:\n",
    "    imbalance_ratio = target_counts.max() / target_counts.min()\n",
    "    print(f\"Imbalance ratio (max/min): {imbalance_ratio:.2f}\")\n",
    "    if imbalance_ratio >= 1.5:\n",
    "        print(\"Aviso: clases potencialmente desbalanceadas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438de963",
   "metadata": {},
   "source": [
    "### 2.3 Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe49669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd8675",
   "metadata": {},
   "source": [
    "Analizando la columna de \"Gender\", se aprecia que hay filas/entradas que no estan definidas y otras donde el valor es NAN, por lo que estas pueden descartarse sin ningun inconveniente ya que no representan un número importante de la muestra. Esta decisión busca evitar la introducción de sesgos al imputar valores sin fundamento estadístico, manteniendo la coherencia y calidad del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f225d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace([\"NAN\", \"NaN\", \"nan\", \"NULL\", \"NONE\", \" \"], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea427b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b207e224",
   "metadata": {},
   "source": [
    "#### 2.3.1 Columna principal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c9db3",
   "metadata": {},
   "source": [
    "Una vez asignados los strings con intención de ser valores nulos, tenemos que la columna de Performance con 6 valores nulos, y al ser la que nos interesa su estudio, es pertinente descartar sus valores nulos dado que estos valores no pueden emplearse para el entrenamiento ni la evaluación del modelo a diseñar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Performance'])\n",
    "df[\"Performance\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709676e0",
   "metadata": {},
   "source": [
    "#### 2.3.2 Columna mixed_type_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3258ec",
   "metadata": {},
   "source": [
    "Asimismo, la columna \"mixed_type_col\" por la cantidad de datos de tipo nulo es muy probable que no aporte algún tipo de valor predictivo para el modelo, ya que su propia entrada mezcla valores de tipo numéricos y de texto. Es por esto que se descartó la columna para evitar ruido en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['mixed_type_col'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93eb5cd",
   "metadata": {},
   "source": [
    "#### 2.3.3 Columnas con datos ordinales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c24983",
   "metadata": {},
   "source": [
    "Las columnas \"Class_X_Percentage\" y \"Class_XII_Percentage\" al ser de tipo ordinal, para no descartar sus valores nulos se les puede asignar el valor de su moda, lo cual no afecta en gran medida al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Class_ X_Percentage': 'Class_X_Percentage'}, inplace=True) # Cambio de nombre de la columna para una mejor manipulación en el notebook\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class_X_Percentage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class_X_Percentage'] = df['Class_X_Percentage'].fillna(\"EXCELLENT\")\n",
    "df[\"Class_X_Percentage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class_XII_Percentage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d143aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class_XII_Percentage'] = df['Class_XII_Percentage'].fillna(\"EXCELLENT\")\n",
    "df[\"Class_XII_Percentage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99708088",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_cols = ['Class_X_Percentage', 'Class_XII_Percentage']\n",
    "# Histogramas + KDE de porcentajes\n",
    "for col in pct_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df[col].dropna(), kde=True, bins=30)\n",
    "    plt.title(f\"Distribución de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Boxplots para detectar atípicos\n",
    "plt.figure(figsize=(max(6, 1.5*len(pct_cols)), 4))\n",
    "sns.boxplot(data=df[pct_cols], orient=\"h\")\n",
    "plt.title(\"Boxplots de porcentajes\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3d7c0",
   "metadata": {},
   "source": [
    "#### 2.3.4 Columnas nominales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e66e4",
   "metadata": {},
   "source": [
    "##### - Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5947d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f65d30f",
   "metadata": {},
   "source": [
    "Al no poder suponer el género del que presenta, se optó por crear un nuevo valor \"MISSING\", el cual no interfiera con la muestra que se tiene y no afecta en gran medida debido a que son 8 datos faltantes de esta columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52205779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].fillna(\"MISSING\")\n",
    "df[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfe60b",
   "metadata": {},
   "source": [
    "Para las demás columnas, sus datos nulos se les asignó el valor correspondiente a sus modas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Caste'] = df['Caste'].fillna(\"GENERAL\")\n",
    "df['coaching'] = df['coaching'].fillna(\"WA\")\n",
    "df['time'] = df['time'].fillna(\"TWO\")\n",
    "df['Class_ten_education'] = df['Class_ten_education'].fillna(\"SEBA\")\n",
    "df['twelve_education'] = df['twelve_education'].fillna(\"AHSEC\")\n",
    "df['medium'] = df['medium'].fillna(\"ENGLISH\")\n",
    "df['Father_occupation'] = df['Father_occupation'].fillna(\"OTHERS\")\n",
    "df['Mother_occupation'] = df['Mother_occupation'].fillna(\"HOUSE_WIFE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fba7581",
   "metadata": {},
   "source": [
    "### 2.3.5 Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea90890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633ccee",
   "metadata": {},
   "source": [
    "Se aprecia que ya no hay valores nulos y se pudieron homogeneizar aquellas entradas que se reconocían similares en el DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af366c90",
   "metadata": {},
   "source": [
    "## 3. Análisis Exploratorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92363375",
   "metadata": {},
   "source": [
    "### 3.1 Gráficos de barras para variables categóricas + cruces con la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d9c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Gender', 'Caste', 'coaching', 'time', 'Class_ten_education', 'twelve_education', 'medium', 'Father_occupation', 'Mother_occupation']\n",
    "# Conteos por categoría\n",
    "for c in cat_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    order = df[c].value_counts().index\n",
    "    sns.countplot(x=c, data=df, order=order)\n",
    "    plt.title(f\"Conteo por categoría: {c}\")\n",
    "    plt.xlabel(c)\n",
    "    plt.ylabel(\"Conteo\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Proporción de rendimiento (stacked) por categórica\n",
    "def plot_stacked_bar_prop(data, cat, target):\n",
    "    ct = pd.crosstab(data[cat], data[target], normalize=\"index\")  # proporción por fila\n",
    "    ct = ct.sort_index()\n",
    "    ct.plot(kind=\"bar\", stacked=True, figsize=(7,4))\n",
    "    plt.title(f\"Proporción de {target} por {cat}\")\n",
    "    plt.xlabel(cat)\n",
    "    plt.ylabel(\"Proporción\")\n",
    "    plt.legend(title=target, bbox_to_anchor=(1,1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for c in cat_cols:\n",
    "    if df[c].notna().sum() > 0:\n",
    "        plot_stacked_bar_prop(df, c, target_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217acda",
   "metadata": {},
   "source": [
    "### 3.2 Matriz de correlación (numéricas) + con objetivo (numérico codificado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd41b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del dataframe para codificar variables\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Codificar variables ordinales (porcentajes)\n",
    "ordinal_mappings = {\n",
    "    'Class_X_Percentage': {'POOR': 1, 'AVERAGE': 2, 'GOOD': 3, 'VG': 4, 'EXCELLENT': 5},\n",
    "    'Class_XII_Percentage': {'POOR': 1, 'AVERAGE': 2, 'GOOD': 3, 'VG': 4, 'EXCELLENT': 5}\n",
    "}\n",
    "\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    df_encoded[col] = df[col].map(mapping)\n",
    "\n",
    "# Codificar variables categóricas nominales con LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_cols = ['Gender', 'Caste', 'coaching', 'time', 'Class_ten_education', \n",
    "                   'twelve_education', 'medium', 'Father_occupation', 'Mother_occupation']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Codificar la variable objetivo\n",
    "target_map = {'POOR': 1, 'AVERAGE': 2, 'GOOD': 3, 'VG': 4, 'EXCELLENT': 5}\n",
    "df_encoded['Performance_num'] = df[target_col].map(target_map)\n",
    "print(\"Mapeo objetivo -> numérico:\", target_map)\n",
    "\n",
    "# Seleccionar todas las columnas numéricas codificadas\n",
    "num_df = df_encoded.select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"\\nColumnas numéricas para correlación: {list(num_df.columns)}\")\n",
    "print(f\"Forma del dataframe numérico: {num_df.shape}\")\n",
    "\n",
    "# Correlación (Pearson)\n",
    "corr = num_df.corr(method=\"pearson\")\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(max(10, 0.8*len(num_df.columns)), max(8, 0.8*len(num_df.columns))))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap=\"coolwarm\", center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title(\"Matriz de correlación (Pearson)\", fontsize=14, pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top correlaciones altas con el objetivo\n",
    "if \"Performance_num\" in corr.columns:\n",
    "    target_corr = corr[\"Performance_num\"].drop(labels=[\"Performance_num\"], errors=\"ignore\").sort_values(ascending=False)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Correlaciones más altas con el objetivo (Performance):\")\n",
    "    print(\"=\"*60)\n",
    "    display(target_corr)\n",
    "\n",
    "# Identificar pares fuertemente correlacionados entre variables (umbral ajustable)\n",
    "def high_corr_pairs(corr_mat, threshold=0.6):\n",
    "    pairs = []\n",
    "    cols = corr_mat.columns\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i+1, len(cols)):\n",
    "            val = corr_mat.iloc[i, j]\n",
    "            if abs(val) >= threshold:\n",
    "                pairs.append((cols[i], cols[j], val))\n",
    "    return sorted(pairs, key=lambda x: -abs(x[2]))\n",
    "\n",
    "pairs = high_corr_pairs(corr, threshold=0.6)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Pares de variables con |correlación| >= 0.6:\")\n",
    "print(\"=\"*60)\n",
    "if pairs:\n",
    "    for a, b, v in pairs[:15]:\n",
    "        print(f\"  {a:30s} — {b:30s}: {v:>6.3f}\")\n",
    "else:\n",
    "    print(\"  No se encontraron pares con correlación >= 0.6\")\n",
    "\n",
    "# Nota: correlación != causalidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f556f87",
   "metadata": {},
   "source": [
    "## 3.3 Detección de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota: Este dataset contiene principalmente variables categóricas y ordinales.\n",
    "# Para detectar outliers, usaremos las versiones codificadas numéricamente de las variables ordinales\n",
    "# creadas en la sección 3.2\n",
    "\n",
    "# Usamos el dataframe codificado del análisis anterior\n",
    "# Seleccionamos solo las columnas que representan variables ordinales codificadas\n",
    "ordinal_encoded_cols = ['Class_X_Percentage', 'Class_XII_Percentage']\n",
    "\n",
    "# Verificar si tenemos columnas numéricas para analizar\n",
    "numeric_ordinal_cols = [col for col in ordinal_encoded_cols if col in df_encoded.columns \n",
    "                        and np.issubdtype(df_encoded[col].dtype, np.number)]\n",
    "\n",
    "if len(numeric_ordinal_cols) == 0:\n",
    "    print(\"=\"*70)\n",
    "    print(\"IMPORTANTE: No hay variables numéricas continuas en este dataset.\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nEste dataset contiene únicamente variables categóricas y ordinales.\")\n",
    "    print(\"Las columnas Class_X_Percentage y Class_XII_Percentage son categorías\")\n",
    "    print(\"ordenadas (POOR, AVERAGE, GOOD, VG, EXCELLENT), no valores numéricos.\")\n",
    "    print(\"\\nPara este tipo de datos, el análisis de outliers mediante IQR\")\n",
    "    print(\"(Interquartile Range) no es aplicable de manera directa.\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Análisis alternativo: Distribución de categorías ordinales\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Mostrar distribución de las variables ordinales\n",
    "    for col in ['Class_X_Percentage', 'Class_XII_Percentage']:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(\"-\" * 50)\n",
    "        counts = df[col].value_counts().sort_index()\n",
    "        display(pd.DataFrame({\n",
    "            'Categoría': counts.index,\n",
    "            'Frecuencia': counts.values,\n",
    "            'Porcentaje': (counts.values / counts.sum() * 100).round(2)\n",
    "        }).reset_index(drop=True))\n",
    "        \n",
    "        # Gráfico de barras\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        order = ['POOR', 'AVERAGE', 'GOOD', 'VG', 'EXCELLENT']\n",
    "        # Filtrar solo las categorías que existen en los datos\n",
    "        order_filtered = [cat for cat in order if cat in counts.index]\n",
    "        sns.countplot(x=col, data=df, order=order_filtered, palette='viridis')\n",
    "        plt.title(f'Distribución de {col}')\n",
    "        plt.xlabel('Categoría de rendimiento')\n",
    "        plt.ylabel('Frecuencia')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Conclusión sobre outliers:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"En variables categóricas ordinales, los 'outliers' se interpretan como\")\n",
    "    print(\"categorías con muy baja frecuencia. En este caso, todas las categorías\")\n",
    "    print(\"presentes representan valores válidos del dominio del problema.\")\n",
    "else:\n",
    "    # Si hay columnas numéricas (caso hipotético para versiones codificadas)\n",
    "    def iqr_outlier_mask(series, k=1.5):\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - k * iqr\n",
    "        upper = q3 + k * iqr\n",
    "        return (series < lower) | (series > upper), lower, upper, q1, q3\n",
    "\n",
    "    outlier_report = []\n",
    "    for col in numeric_ordinal_cols:\n",
    "        s = df_encoded[col].dropna()\n",
    "        if s.empty: \n",
    "            continue\n",
    "        mask, lower, upper, q1, q3 = iqr_outlier_mask(s, k=1.5)\n",
    "        count_out = mask.sum()\n",
    "        outlier_report.append({\n",
    "            \"col\": col,\n",
    "            \"q1\": q1, \"q3\": q3, \"iqr\": q3-q1,\n",
    "            \"lower_bound\": lower, \"upper_bound\": upper,\n",
    "            \"outliers\": int(count_out), \"pct_outliers\": round(100*count_out/len(s), 2)\n",
    "        })\n",
    "\n",
    "    outlier_df = pd.DataFrame(outlier_report).sort_values(by=\"pct_outliers\", ascending=False)\n",
    "    display(outlier_df)\n",
    "\n",
    "    # Visual de outliers (boxplots individuales)\n",
    "    for col in numeric_ordinal_cols:\n",
    "        plt.figure(figsize=(5,4))\n",
    "        sns.boxplot(y=df_encoded[col])\n",
    "        plt.title(f\"Outliers (IQR) - {col}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc78fb",
   "metadata": {},
   "source": [
    "## 4. Guardar Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Guardar dataset limpio y listo para comparar ===\n",
    "OUTPUT_PATH = \"../data/processed\"\n",
    "OUTPUT_FILENAME = \"student_entry_performance_modified_after_eda.csv\"\n",
    "OUTPUT_FULL_PATH = f\"{OUTPUT_PATH}/{OUTPUT_FILENAME}\"\n",
    "df.to_csv(OUTPUT_FULL_PATH, index=False)\n",
    "print(f\"Dataset modificado guardado en: {OUTPUT_FULL_PATH}\")\n",
    "print(f\"Filas finales: {len(df)} | Columnas: {len(df.columns)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PySpark Env)",
   "language": "python",
   "name": "env-pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
