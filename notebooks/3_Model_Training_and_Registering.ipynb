{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f44e41",
   "metadata": {},
   "source": [
    "---\n",
    "### üì¶ Informaci√≥n de Versionado con DVC y MLflow\n",
    "\n",
    "**Este notebook es el PASO 3 del pipeline:**\n",
    "1. Lee: `data/processed/student_performance_features.csv` (versi√≥n con features - `data-v1.2-features`)\n",
    "2. Entrena: Modelos LightGBM, XGBoost y CatBoost\n",
    "3. Registra: Experimentos y m√©tricas con MLflow\n",
    "4. Guarda: Modelos entrenados (versionados con DVC)\n",
    "\n",
    "**‚ö†Ô∏è Prerrequisitos:**\n",
    "1. ‚úÖ Haber ejecutado: `1_EDA_and_Cleaning.ipynb`\n",
    "2. ‚úÖ Haber ejecutado: `2_Data_Processing.ipynb`\n",
    "3. ‚úÖ Haber versionado los resultados con DVC\n",
    "\n",
    "**Para obtener el dataset correcto:**\n",
    "```bash\n",
    "# Si tu compa√±ero ya lo proces√≥, descarga la versi√≥n con features\n",
    "dvc pull\n",
    "\n",
    "# O aseg√∫rate de estar en la versi√≥n correcta\n",
    "git checkout data-v1.2-features\n",
    "dvc checkout\n",
    "```\n",
    "\n",
    "**Versionado de modelos:**\n",
    "Este notebook usa MLflow para trackear experimentos, pero los modelos finales tambi√©n se versionan con DVC para tener un control completo del pipeline.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc110d",
   "metadata": {},
   "source": [
    "# Model Training and Registering\n",
    "\n",
    "Este notebook est√° dedicado al entrenamiento de modelos de machine learning utilizando el dataset obtenido tras las tareas de preprocesamiento. El objetivo es resolver un problema cuya variable obejtivo es una variable categ√≥rica ordinal, por lo que se explorar√°n diferentes algoritmos para identificar el que mejor se adapte a nuestros datos.\n",
    "\n",
    "En primer lugar, se propondr√°n tres modelos de clasificaci√≥n: \n",
    "* LightGBM: Algoritmo basado en √°rboles de decisi√≥n optimizado para velocidad y eficiencia, especialmente √∫til en grandes conjuntos de datos y capaz de manejar variables categ√≥ricas y ordinales.\n",
    "* XGBoost: Implementaci√≥n avanzada de gradient boosting que destaca por su regularizaci√≥n y manejo eficiente de datos dispersos, logrando alto rendimiento en tareas de clasificaci√≥n y regresi√≥n.\n",
    "* CatBoosting: Algoritmo de boosting desarrollado por Yandex, dise√±ado para trabajar de forma nativa con variables categ√≥ricas y evitar el overfitting, ofreciendo excelentes resultados en problemas con datos heterog√©neos.\n",
    "\n",
    "Cada uno ser√° entrenado y evaluado adem√°s se les dar√° seguimiento a sus experiment runs asociadas mediante MLflow para asegurar la trazabilidad de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76d5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score, root_mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eced2f9",
   "metadata": {},
   "source": [
    "**funci√≥n auxiliar para logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbc408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "def get_logger(name: str = __name__, log_file: Optional[str] = None, level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Create and configure a logger with optional file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        name (str): Logger name (usually __name__).\n",
    "        log_file (str, optional): Path to a file to log messages.\n",
    "        level (int): Logging level (default: INFO).\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: Configured logger instance.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    if not logger.handlers:  # Prevent duplicate handlers in Jupyter or repeated calls\n",
    "        formatter = logging.Formatter(\n",
    "            fmt=\"[%(asctime)s | %(levelname)s ] %(name)s -> %(message)s\",\n",
    "            datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "\n",
    "        # Console handler\n",
    "        console_handler = logging.StreamHandler(sys.stdout)\n",
    "        console_handler.setFormatter(formatter)\n",
    "        logger.addHandler(console_handler)\n",
    "\n",
    "        # Optional file handler\n",
    "        if log_file:\n",
    "            file_handler = logging.FileHandler(log_file)\n",
    "            file_handler.setFormatter(formatter)\n",
    "            logger.addHandler(file_handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9cf2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el logger\n",
    "logger = get_logger(\"mlflow experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da460884",
   "metadata": {},
   "source": [
    "# Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541ba23",
   "metadata": {},
   "source": [
    "## Lectura del conjunto de entrenamiento\n",
    "\n",
    "La variable objetivo, \"Performance\", es una variable categ√≥rica ordinal, lo que implica que sus categor√≠as tienen un orden inherente pero no una distancia cuantificable entre ellas. Para abordar este tipo de problema, emplearemos algoritmos que permiten modelar la ordinalidad de la variable, como LightGBM, XGBoost y CatBoost. \n",
    "\n",
    "Es fundamental configurar correctamente los par√°metros de estos modelos: \n",
    " * en LightGBM se debe establecer el par√°metro `objective` como `\"multiclass\"` o `\"multiclassova\"` y, para ordinalidad, considerar el uso de la variante `lgbm.rank` si se desea modelar el orden.\n",
    " * en XGBoost, el par√°metro `objective` debe ser `\"multi:softprob\"` para clasificaci√≥n multiclase; \n",
    " * en CatBoost, se puede utilizar el par√°metro `loss_function=\"MultiClass\"` y, para ordinalidad, el modo `\"YetiRank\"` o `\"Ordinal\"` si se requiere modelar el orden expl√≠citamente. \n",
    " \n",
    " Adem√°s, es necesario especificar el n√∫mero de clases (`num_class` o `classes_count`) y asegurarse de que la codificaci√≥n de la variable objetivo respete el orden natural de las categor√≠as. Estas configuraciones permiten que los modelos aprovechen la informaci√≥n ordinal y mejoren la capacidad predictiva en este contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14263d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.803234</td>\n",
       "      <td>-0.597979</td>\n",
       "      <td>-0.285577</td>\n",
       "      <td>-0.770143</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>-0.063243</td>\n",
       "      <td>-0.451023</td>\n",
       "      <td>-0.984059</td>\n",
       "      <td>-0.048342</td>\n",
       "      <td>-0.116927</td>\n",
       "      <td>0.258324</td>\n",
       "      <td>-0.415056</td>\n",
       "      <td>-0.299239</td>\n",
       "      <td>-0.045746</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.383741</td>\n",
       "      <td>-0.558693</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>1.081237</td>\n",
       "      <td>1.002544</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.260944</td>\n",
       "      <td>0.398450</td>\n",
       "      <td>-0.258088</td>\n",
       "      <td>0.143168</td>\n",
       "      <td>0.352092</td>\n",
       "      <td>0.023940</td>\n",
       "      <td>0.116888</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>-0.081184</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.665234</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.910224</td>\n",
       "      <td>-0.979597</td>\n",
       "      <td>0.610582</td>\n",
       "      <td>0.515577</td>\n",
       "      <td>0.055653</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>0.367403</td>\n",
       "      <td>0.276059</td>\n",
       "      <td>0.247405</td>\n",
       "      <td>0.025235</td>\n",
       "      <td>0.048601</td>\n",
       "      <td>0.496631</td>\n",
       "      <td>-0.060994</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.507289</td>\n",
       "      <td>-1.468973</td>\n",
       "      <td>-0.208351</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>0.318739</td>\n",
       "      <td>-0.599155</td>\n",
       "      <td>0.271468</td>\n",
       "      <td>0.029258</td>\n",
       "      <td>0.281890</td>\n",
       "      <td>0.145417</td>\n",
       "      <td>0.155879</td>\n",
       "      <td>-0.050884</td>\n",
       "      <td>-0.074240</td>\n",
       "      <td>0.066675</td>\n",
       "      <td>-0.163159</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.676385</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>0.672490</td>\n",
       "      <td>-0.781445</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>-0.421630</td>\n",
       "      <td>0.204497</td>\n",
       "      <td>0.090873</td>\n",
       "      <td>-0.031931</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>-0.248873</td>\n",
       "      <td>-0.298813</td>\n",
       "      <td>-0.188266</td>\n",
       "      <td>0.556631</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  0.803234 -0.597979 -0.285577 -0.770143 -0.017667  0.023372 -0.063243   \n",
       "1  0.383741 -0.558693  0.664729  1.081237  1.002544 -0.000102  0.260944   \n",
       "2  0.665234  0.025918  0.910224 -0.979597  0.610582  0.515577  0.055653   \n",
       "3  0.507289 -1.468973 -0.208351  0.967490  0.318739 -0.599155  0.271468   \n",
       "4  0.676385  0.010505  0.672490 -0.781445 -0.002355 -0.421630  0.204497   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0 -0.451023 -0.984059 -0.048342 -0.116927  0.258324 -0.415056 -0.299239   \n",
       "1  0.398450 -0.258088  0.143168  0.352092  0.023940  0.116888  0.069941   \n",
       "2  0.029394  0.367403  0.276059  0.247405  0.025235  0.048601  0.496631   \n",
       "3  0.029258  0.281890  0.145417  0.155879 -0.050884 -0.074240  0.066675   \n",
       "4  0.090873 -0.031931  0.006785 -0.248873 -0.298813 -0.188266  0.556631   \n",
       "\n",
       "       PC15  Performance  \n",
       "0 -0.045746            3  \n",
       "1 -0.081184            3  \n",
       "2 -0.060994            3  \n",
       "3 -0.163159            3  \n",
       "4  0.750617            3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Leer dataset de features versionado con DVC ===\n",
    "# Este archivo debe ser la versi√≥n data-v1.2-features (despu√©s de feature engineering)\n",
    "DATA_PATH = \"../data/processed/student_performance_features.csv\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìÇ PASO 3: Cargando dataset de features para entrenamiento\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Archivo: {DATA_PATH}\")\n",
    "print(\"üí° Este archivo est√° versionado con DVC (data-v1.2-features)\")\n",
    "print(\"üí° Aseg√∫rate de tener la versi√≥n correcta con: dvc pull\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"‚úÖ Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "print(f\"üìä Features: {df.shape[1]-1} componentes PCA + 1 target (Performance)\")\n",
    "print(\"=\"*70)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f414d",
   "metadata": {},
   "source": [
    "## Separaci√≥n en Conjunto de entrenamiento y prueba -estratificado-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085e3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Performance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d2c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, matriz de caracteristicas\n",
    "X = df.drop(columns=[target_column])\n",
    "# y, vairable objetivo\n",
    "y = df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c583d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separaci√≥n en conjunto de entrenamient y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=13,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8eb09",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "El flujo b√°sico de MLflow para la gesti√≥n de experimentos de machine learning consta de cuatro pasos fundamentales. \n",
    "\n",
    "**1. Definici√≥n del experimento:** Antes de iniciar cualquier entrenamiento, se debe crear o seleccionar un experimento en MLflow mediante `mlflow.create_experiment()` o `mlflow.set_experiment()` o `mlflow.get_experiment_by_name(experiment_name)`. Esto permite agrupar y organizar los diferentes intentos de entrenamiento bajo un mismo contexto, facilitando la trazabilidad y comparaci√≥n de resultados. \n",
    "\n",
    "**2. Ejecuci√≥n de una corrida (run) dentro del experimento:** Cada entrenamiento de modelo se encapsula en una \"run\", iniciada con `mlflow.start_run()`. Una run representa una ejecuci√≥n individual, donde se pueden registrar todos los artefactos y m√©tricas asociados. \n",
    "\n",
    "**3. Logging de par√°metros, m√©tricas y artefactos:** Durante la run, se emplean funciones como `mlflow.log_params()`, `mlflow.log_metrics()` y `mlflow.log_artifact()` para guardar los hiperpar√°metros utilizados, las m√©tricas de desempe√±o obtenidas y cualquier archivo relevante (por ejemplo, el modelo entrenado o gr√°ficos de evaluaci√≥n). Este registro estructurado permite auditar y reproducir los experimentos f√°cilmente. \n",
    "\n",
    "**4. Registro del modelo:** Una vez identificado el mejor modelo, se utiliza `mlflow.register_model()` para almacenarlo en el Model Registry de MLflow. Esto habilita la gesti√≥n de versiones, la transici√≥n entre estados (staging, production, archived) y el despliegue controlado del modelo, asegurando que el ciclo de vida del modelo est√© completamente documentado y gestionado. Este flujo garantiza la reproducibilidad, trazabilidad y gobernanza de los modelos desarrollados.\n",
    "\n",
    "\n",
    "Es por ello que se ha decidido dise√±ar la funci√≥n `evaluate_and_log_model()`. esta funci√≥n trata de los siguiente:\n",
    "\n",
    "Claro, aqu√≠ tienes una explicaci√≥n paso a paso de lo que hace la funci√≥n `evaluate_and_log_model`:\n",
    "\n",
    "1. **Recibe los argumentos**:  \n",
    "    - Nombre del modelo, instancia del modelo, datos de entrenamiento y prueba, par√°metros, nombre del experimento MLflow y logger.\n",
    "\n",
    "2. **Busca o crea el experimento en MLflow**:  \n",
    "    - Si el experimento no existe, lo crea.  \n",
    "    - Si ya existe, lo reutiliza.  \n",
    "    - Informa por el logger qu√© experimento se est√° usando.\n",
    "\n",
    "3. **Inicia una corrida (run) en MLflow**:  \n",
    "    - Cada entrenamiento se encapsula en una run para registrar resultados.\n",
    "\n",
    "4. **Loguea los par√°metros del modelo**:  \n",
    "    - Si se pasan par√°metros, los registra en MLflow y lo informa por el logger.\n",
    "\n",
    "5. **Entrena el modelo**:  \n",
    "    - Ajusta el modelo con los datos de entrenamiento (`fit`).  \n",
    "    - Informa por el logger que el entrenamiento termin√≥.\n",
    "\n",
    "6. **Realiza predicciones**:  \n",
    "    - Predice sobre el conjunto de prueba.  \n",
    "    - Redondea las predicciones para obtener clases enteras.\n",
    "\n",
    "7. **Calcula m√©tricas**:  \n",
    "    - Calcula el RMSE (error cuadr√°tico medio ra√≠z) entre las predicciones y los valores reales.  \n",
    "    - Calcula el QWK (Cohen‚Äôs Kappa ponderado cuadr√°tico) para evaluar la calidad de la clasificaci√≥n ordinal.\n",
    "\n",
    "8. **Registra las m√©tricas en MLflow**:  \n",
    "    - Loguea RMSE y QWK en MLflow.  \n",
    "    - Informa por el logger los valores obtenidos.\n",
    "\n",
    "9. **Guarda el modelo en MLflow**:  \n",
    "    - Registra el modelo entrenado como artefacto en MLflow.  \n",
    "    - Informa por el logger que el modelo fue guardado.\n",
    "\n",
    "10. **Devuelve las m√©tricas**:  \n",
    "     - Retorna RMSE y QWK para su uso posterior.\n",
    "\n",
    "\n",
    "**M√©tricas utilizadas: RMSE y QWK**\n",
    "\n",
    "- **RMSE (Root Mean Squared Error):**  \n",
    "    El RMSE es una m√©trica que mide la diferencia promedio entre los valores predichos por el modelo y los valores reales, penalizando m√°s fuertemente los errores grandes. Se calcula como la ra√≠z cuadrada de la media de los errores al cuadrado. En problemas de regresi√≥n y clasificaci√≥n ordinal, el RMSE permite cuantificar qu√© tan cerca est√°n las predicciones de los valores verdaderos, siendo √∫til para evaluar modelos que predicen valores continuos o clases ordenadas. Un RMSE bajo indica que el modelo realiza predicciones precisas.\n",
    "\n",
    "- **QWK (Quadratic Weighted Kappa):**  \n",
    "    El QWK es una m√©trica dise√±ada para evaluar la concordancia entre dos clasificadores (por ejemplo, las predicciones del modelo y las etiquetas reales) en problemas de clasificaci√≥n ordinal. Considera no solo si la predicci√≥n es correcta, sino tambi√©n cu√°n lejos est√° la predicci√≥n de la clase verdadera, penalizando m√°s los errores grandes. El QWK toma valores entre -1 y 1, donde 1 indica perfecta concordancia, 0 indica concordancia aleatoria y valores negativos indican peor que aleatorio. Es especialmente relevante en contextos donde las clases tienen un orden natural, como en este caso.\n",
    "\n",
    "Estas m√©tricas permiten comparar objetivamente el desempe√±o de los modelos en la predicci√≥n de la variable ordinal \"Performance\", asegurando que tanto la precisi√≥n como el respeto por el orden de las categor√≠as sean considerados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785920d8",
   "metadata": {},
   "source": [
    "## Funci√≥n auxiliar para el logging con MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8006de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_log_model(\n",
    "    model_name,\n",
    "    model,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    params=None,\n",
    "    experiment_name=\"Default_Experiment\",\n",
    "    logger=None,\n",
    "    tracking_dir=\"../data/mlflow\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train model, log metrics, parameters, and model artifact to MLflow.\n",
    "    Automatically creates or reuses an MLflow experiment by name.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model/run.\n",
    "        model: Untrained model instance (e.g., sklearn model).\n",
    "        X_train, X_test, y_train, y_test: Training/testing data.\n",
    "        params (dict, optional): Model parameters to log.\n",
    "        experiment_name (str): MLflow experiment name.\n",
    "        logger (logging.Logger, optional): Logger for status messages.\n",
    "        tracking_dir (str): Local path to store MLflow tracking data.\n",
    "    \"\"\"\n",
    "    # --- Ensure MLflow uses the desired local folder ---\n",
    "    mlflow.set_tracking_uri(f\"file:{tracking_dir}\")\n",
    "    if logger:\n",
    "        logger.info(f\"MLflow tracking directory set to: {tracking_dir}\")\n",
    "\n",
    "    # --- Handle experiment setup ---\n",
    "    existing_experiment = mlflow.get_experiment_by_name(name=experiment_name)\n",
    "    if existing_experiment is None:\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            name=experiment_name,\n",
    "            tags={\"owner\": \"equipo36\", \"project\": \"student-performance-prediction\"}\n",
    "        )\n",
    "        if logger:\n",
    "            logger.info(f\"Created new MLflow experiment: '{experiment_name}' (ID: {experiment_id})\")\n",
    "    else:\n",
    "        experiment_id = existing_experiment.experiment_id\n",
    "        if logger:\n",
    "            logger.info(f\"Using existing MLflow experiment: '{experiment_name}' (ID: {experiment_id})\")\n",
    "\n",
    "    # --- Start MLflow run ---\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=model_name):\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "            if logger:\n",
    "                logger.info(f\"Logged parameters for {model_name}: {params}\")\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        if logger:\n",
    "            logger.info(f\"Model '{model_name}' training complete.\")\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_class = np.rint(y_pred).astype(int)\n",
    "\n",
    "        # Compute metrics\n",
    "        rmse = root_mean_squared_error(y_test, y_pred_class)\n",
    "        qwk = cohen_kappa_score(y_test, y_pred_class, weights=\"quadratic\")\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"quadratic_weighted_kappa\", qwk)\n",
    "        if logger:\n",
    "            logger.info(f\"Metrics logged ‚Äî RMSE: {rmse:.4f}, QWK: {qwk:.4f}\")\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, artifact_path=\"model\", input_example=X_test.iloc[:5])\n",
    "        if logger:\n",
    "            logger.info(f\"Model '{model_name}' logged to MLflow under experiment '{experiment_name}'.\")\n",
    "\n",
    "        return rmse, qwk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a2c16",
   "metadata": {},
   "source": [
    "## MLFlow server\n",
    "\n",
    "MLflow server es una herramienta que permite gestionar y monitorizar experimentos de machine learning de forma centralizada. Su prop√≥sito principal es almacenar los resultados, par√°metros, m√©tricas y modelos generados durante el ciclo de vida de los experimentos, facilitando la trazabilidad, comparaci√≥n y reproducibilidad. Al ejecutar el servidor MLflow, se habilita una interfaz web donde los usuarios pueden visualizar y administrar todos los experimentos registrados en la plataforma.\n",
    "\n",
    "En la celda siguiente, podemos encontrar c√≥digo que nos ayuda a levantar el server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0cf6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow server started at http://127.0.0.1:8080\n"
     ]
    }
   ],
   "source": [
    "import subprocess, time, os, signal\n",
    "\n",
    "# Configuration\n",
    "MLFLOW_HOST = \"127.0.0.1\"\n",
    "MLFLOW_PORT = 8080\n",
    "\n",
    "# Start the MLflow server in background\n",
    "mlflow_process = subprocess.Popen(\n",
    "    [\n",
    "        \"mlflow\", \"server\",\n",
    "        \"--host\", MLFLOW_HOST,\n",
    "        \"--port\", str(MLFLOW_PORT),\n",
    "    ],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ MLflow server started at http://{MLFLOW_HOST}:{MLFLOW_PORT}\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066aaeb8",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146d5d9",
   "metadata": {},
   "source": [
    "### Definici√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349064d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LightGBM params\n",
    "params_lgb = {\n",
    "    'objective': 'regression',    # or 'rmse' ‚Äî continuous ordinal target\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 13\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model_lgb = lgb.LGBMRegressor(**params_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7970ca",
   "metadata": {},
   "source": [
    "### Entrenamiento y logging con mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f30ad62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:06 | INFO ] mlflow experiments -> MLflow tracking directory set to: ../data/mlflow\n",
      "[2025-10-12 18:05:06 | INFO ] mlflow experiments -> Created new MLflow experiment: 'mlflow-student-performance-experiment' (ID: 155893811526728657)\n",
      "[2025-10-12 18:05:06 | INFO ] mlflow experiments -> Logged parameters for LightGBM: {'objective': 'regression', 'metric': 'rmse', 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1, 'random_state': 13}\n",
      "[2025-10-12 18:05:08 | INFO ] mlflow experiments -> Model 'LightGBM' training complete.\n",
      "[2025-10-12 18:05:08 | INFO ] mlflow experiments -> Metrics logged ‚Äî RMSE: 0.8819, QWK: 0.5097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/12 18:05:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\81083075\\Documents\\ML Projects\\MLOps\\equipo36mlops\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:30 | INFO ] mlflow experiments -> Model 'LightGBM' logged to MLflow under experiment 'mlflow-student-performance-experiment'.\n"
     ]
    }
   ],
   "source": [
    "lgb_rmse, lgb_qwk = evaluate_and_log_model(\n",
    "    experiment_name=\"mlflow-student-performance-experiment\",\n",
    "    model_name=\"LightGBM\",\n",
    "    model=model_lgb,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    params=params_lgb,\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03656430",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe8040",
   "metadata": {},
   "source": [
    "### Definici√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "215b749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n del modelo\n",
    "# NOTE: Usamos un diccionario para definir los hiperpar√°metros del modelo\n",
    "params_xgb = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'random_state': 13\n",
    "}\n",
    "# Instanciamos el modelo\n",
    "model_xgb = xgb.XGBRegressor(**params_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e1cb5",
   "metadata": {},
   "source": [
    "### Entrenamiento y loggeo con mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ff234f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:30 | INFO ] mlflow experiments -> MLflow tracking directory set to: ../data/mlflow\n",
      "[2025-10-12 18:05:30 | INFO ] mlflow experiments -> Using existing MLflow experiment: 'mlflow-student-performance-experiment' (ID: 155893811526728657)\n",
      "[2025-10-12 18:05:30 | INFO ] mlflow experiments -> Logged parameters for XGBoost: {'objective': 'reg:squarederror', 'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 6, 'random_state': 13}\n",
      "[2025-10-12 18:05:32 | INFO ] mlflow experiments -> Model 'XGBoost' training complete.\n",
      "[2025-10-12 18:05:32 | INFO ] mlflow experiments -> Metrics logged ‚Äî RMSE: 0.8477, QWK: 0.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/12 18:05:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:37 | INFO ] mlflow experiments -> Model 'XGBoost' logged to MLflow under experiment 'mlflow-student-performance-experiment'.\n"
     ]
    }
   ],
   "source": [
    "xgb_rmse, xgb_qwk = evaluate_and_log_model(\n",
    "    experiment_name=\"mlflow-student-performance-experiment\",\n",
    "    model_name=\"XGBoost\",\n",
    "    model=model_xgb,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    params=params_xgb,\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3952e69",
   "metadata": {},
   "source": [
    "## CatBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9cfaf",
   "metadata": {},
   "source": [
    "### Definici√≥n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e96fce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CatBoost parameters\n",
    "params_cat = {\n",
    "    'iterations': 300,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',   # Continuous target, respects ordering\n",
    "    'random_seed': 42,\n",
    "    'verbose': 0,\n",
    "    'od_type': 'Iter',         # Enable early stopping\n",
    "    'od_wait': 20\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model_cat = CatBoostRegressor(**params_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6880f745",
   "metadata": {},
   "source": [
    "### Entrenamiento y loggeo con mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f1e3206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:37 | INFO ] mlflow experiments -> MLflow tracking directory set to: ../data/mlflow\n",
      "[2025-10-12 18:05:37 | INFO ] mlflow experiments -> Using existing MLflow experiment: 'mlflow-student-performance-experiment' (ID: 155893811526728657)\n",
      "[2025-10-12 18:05:37 | INFO ] mlflow experiments -> Logged parameters for CatBoost: {'iterations': 300, 'learning_rate': 0.05, 'depth': 6, 'loss_function': 'RMSE', 'random_seed': 42, 'verbose': 0, 'od_type': 'Iter', 'od_wait': 20}\n",
      "[2025-10-12 18:05:38 | INFO ] mlflow experiments -> Model 'CatBoost' training complete.\n",
      "[2025-10-12 18:05:38 | INFO ] mlflow experiments -> Metrics logged ‚Äî RMSE: 0.9108, QWK: 0.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/12 18:05:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:42 | INFO ] mlflow experiments -> Model 'CatBoost' logged to MLflow under experiment 'mlflow-student-performance-experiment'.\n"
     ]
    }
   ],
   "source": [
    "cat_rmse, cat_qwk = evaluate_and_log_model(\n",
    "    experiment_name=\"mlflow-student-performance-experiment\",\n",
    "    model_name=\"CatBoost\",\n",
    "    model=model_cat,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    params=params_cat,\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06008358",
   "metadata": {},
   "source": [
    "# Finalmente\n",
    "\n",
    "Detenemos el servidor de MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817aa384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'mlflow_process' in locals() and mlflow_process.poll() is None:\n",
    "#     os.kill(mlflow_process.pid, signal.SIGTERM)\n",
    "#     print(\"üõë MLflow server stopped.\")\n",
    "# else:\n",
    "#     print(\"MLflow server was not running or already stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78327756",
   "metadata": {},
   "source": [
    "## üì¶ Versionar Experimentos MLflow con DVC\n",
    "\n",
    "Una vez que hayas terminado de entrenar y evaluar los modelos, es recomendable versionar los experimentos y artefactos de MLflow con DVC para tener un registro completo del pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Versionar directorio MLflow con DVC ===\n",
    "MLFLOW_PATH = \"../data/mlflow\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ PASO 3 COMPLETADO: Modelos entrenados y registrados en MLflow\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìÇ Directorio MLflow: {MLFLOW_PATH}\")\n",
    "print(f\"üìä Experimentos registrados: LightGBM, XGBoost, CatBoost\")\n",
    "print(f\"üìà M√©tricas: RMSE y QWK (Quadratic Weighted Kappa)\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì¶ SIGUIENTE PASO: Versionar experimentos MLflow con DVC\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüöÄ Ejecuta este comando en la terminal:\\n\")\n",
    "print(f\"bash add_to_dvc.sh {MLFLOW_PATH} models-v1.0-baseline 'Baseline models: LightGBM, XGBoost, CatBoost'\")\n",
    "print(\"\\nüí° O si prefieres hacerlo manualmente:\")\n",
    "print(f\"dvc add {MLFLOW_PATH}\")\n",
    "print(f\"git add {MLFLOW_PATH}.dvc .gitignore\")\n",
    "print('git commit -m \"feat: version models - baseline models trained\"')\n",
    "print('git tag -a \"models-v1.0-baseline\" -m \"Baseline models: LightGBM, XGBoost, CatBoost\"')\n",
    "print(\"dvc push\")\n",
    "print(\"git push origin $(git rev-parse --abbrev-ref HEAD) --tags\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ Pipeline MLOps completo con versionado de datos y modelos!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìå Resumen de versiones:\")\n",
    "print(\"  ‚Ä¢ data-v1.0-raw:      Dataset original sin procesar\")\n",
    "print(\"  ‚Ä¢ data-v1.1-cleaned:  Dataset despu√©s de EDA y limpieza\")\n",
    "print(\"  ‚Ä¢ data-v1.2-features: Dataset con features engineered (PCA)\")\n",
    "print(\"  ‚Ä¢ models-v1.0-baseline: Modelos baseline entrenados\")\n",
    "print(\"\\nüí° Para recuperar cualquier versi√≥n:\")\n",
    "print(\"  git checkout <tag-name>\")\n",
    "print(\"  dvc checkout\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e956e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
