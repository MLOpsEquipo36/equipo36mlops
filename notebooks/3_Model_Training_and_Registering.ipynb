{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f44e41",
   "metadata": {},
   "source": [
    "---\n",
    "### ðŸ“¦ InformaciÃ³n de Versionado con DVC y MLflow\n",
    "\n",
    "**Este notebook es el PASO 3 del pipeline:**\n",
    "1. Lee: `data/processed/student_performance_features.csv` (versiÃ³n con features - `data-v1.2-features`)\n",
    "2. Entrena: Modelos LightGBM, XGBoost y CatBoost\n",
    "3. Registra: Experimentos y mÃ©tricas con MLflow\n",
    "4. Guarda: Modelos entrenados (versionados con DVC)\n",
    "\n",
    "**âš ï¸ Prerrequisitos:**\n",
    "1. âœ… Haber ejecutado: `1_EDA_and_Cleaning.ipynb`\n",
    "2. âœ… Haber ejecutado: `2_Data_Processing.ipynb`\n",
    "3. âœ… Haber versionado los resultados con DVC\n",
    "\n",
    "**Para obtener el dataset correcto:**\n",
    "```bash\n",
    "# Si tu compaÃ±ero ya lo procesÃ³, descarga la versiÃ³n con features\n",
    "dvc pull\n",
    "\n",
    "# O asegÃºrate de estar en la versiÃ³n correcta\n",
    "git checkout data-v1.2-features\n",
    "dvc checkout\n",
    "```\n",
    "\n",
    "**Versionado de modelos:**\n",
    "Este notebook usa MLflow para trackear experimentos, pero los modelos finales tambiÃ©n se versionan con DVC para tener un control completo del pipeline.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc110d",
   "metadata": {},
   "source": [
    "# Model Training and Registering\n",
    "\n",
    "Este notebook estÃ¡ dedicado al entrenamiento de modelos de machine learning utilizando el dataset obtenido tras las tareas de preprocesamiento. El objetivo es resolver un problema cuya variable obejtivo es una variable categÃ³rica ordinal, por lo que se explorarÃ¡n diferentes algoritmos para identificar el que mejor se adapte a nuestros datos.\n",
    "\n",
    "En primer lugar, se propondrÃ¡n tres modelos de clasificaciÃ³n: \n",
    "* LightGBM: Algoritmo basado en Ã¡rboles de decisiÃ³n optimizado para velocidad y eficiencia, especialmente Ãºtil en grandes conjuntos de datos y capaz de manejar variables categÃ³ricas y ordinales.\n",
    "* XGBoost: ImplementaciÃ³n avanzada de gradient boosting que destaca por su regularizaciÃ³n y manejo eficiente de datos dispersos, logrando alto rendimiento en tareas de clasificaciÃ³n y regresiÃ³n.\n",
    "* CatBoosting: Algoritmo de boosting desarrollado por Yandex, diseÃ±ado para trabajar de forma nativa con variables categÃ³ricas y evitar el overfitting, ofreciendo excelentes resultados en problemas con datos heterogÃ©neos.\n",
    "\n",
    "Cada uno serÃ¡ entrenado y evaluado ademÃ¡s se les darÃ¡ seguimiento a sus experiment runs asociadas mediante MLflow para asegurar la trazabilidad de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76d5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score, root_mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eced2f9",
   "metadata": {},
   "source": [
    "**funciÃ³n auxiliar para logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbc408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "def get_logger(name: str = __name__, log_file: Optional[str] = None, level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Create and configure a logger with optional file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        name (str): Logger name (usually __name__).\n",
    "        log_file (str, optional): Path to a file to log messages.\n",
    "        level (int): Logging level (default: INFO).\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: Configured logger instance.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    if not logger.handlers:  # Prevent duplicate handlers in Jupyter or repeated calls\n",
    "        formatter = logging.Formatter(\n",
    "            fmt=\"[%(asctime)s | %(levelname)s ] %(name)s -> %(message)s\",\n",
    "            datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "\n",
    "        # Console handler\n",
    "        console_handler = logging.StreamHandler(sys.stdout)\n",
    "        console_handler.setFormatter(formatter)\n",
    "        logger.addHandler(console_handler)\n",
    "\n",
    "        # Optional file handler\n",
    "        if log_file:\n",
    "            file_handler = logging.FileHandler(log_file)\n",
    "            file_handler.setFormatter(formatter)\n",
    "            logger.addHandler(file_handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9cf2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el logger\n",
    "logger = get_logger(\"mlflow experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da460884",
   "metadata": {},
   "source": [
    "# Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541ba23",
   "metadata": {},
   "source": [
    "## Lectura del conjunto de entrenamiento\n",
    "\n",
    "La variable objetivo, \"Performance\", es una variable categÃ³rica ordinal, lo que implica que sus categorÃ­as tienen un orden inherente pero no una distancia cuantificable entre ellas. Para abordar este tipo de problema, emplearemos algoritmos que permiten modelar la ordinalidad de la variable, como LightGBM, XGBoost y CatBoost. \n",
    "\n",
    "Es fundamental configurar correctamente los parÃ¡metros de estos modelos: \n",
    " * en LightGBM se debe establecer el parÃ¡metro `objective` como `\"multiclass\"` o `\"multiclassova\"` y, para ordinalidad, considerar el uso de la variante `lgbm.rank` si se desea modelar el orden.\n",
    " * en XGBoost, el parÃ¡metro `objective` debe ser `\"multi:softprob\"` para clasificaciÃ³n multiclase; \n",
    " * en CatBoost, se puede utilizar el parÃ¡metro `loss_function=\"MultiClass\"` y, para ordinalidad, el modo `\"YetiRank\"` o `\"Ordinal\"` si se requiere modelar el orden explÃ­citamente. \n",
    " \n",
    " AdemÃ¡s, es necesario especificar el nÃºmero de clases (`num_class` o `classes_count`) y asegurarse de que la codificaciÃ³n de la variable objetivo respete el orden natural de las categorÃ­as. Estas configuraciones permiten que los modelos aprovechen la informaciÃ³n ordinal y mejoren la capacidad predictiva en este contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14263d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.803234</td>\n",
       "      <td>-0.597979</td>\n",
       "      <td>-0.285577</td>\n",
       "      <td>-0.770143</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>-0.063243</td>\n",
       "      <td>-0.451023</td>\n",
       "      <td>-0.984059</td>\n",
       "      <td>-0.048342</td>\n",
       "      <td>-0.116927</td>\n",
       "      <td>0.258324</td>\n",
       "      <td>-0.415056</td>\n",
       "      <td>-0.299239</td>\n",
       "      <td>-0.045746</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.383741</td>\n",
       "      <td>-0.558693</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>1.081237</td>\n",
       "      <td>1.002544</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.260944</td>\n",
       "      <td>0.398450</td>\n",
       "      <td>-0.258088</td>\n",
       "      <td>0.143168</td>\n",
       "      <td>0.352092</td>\n",
       "      <td>0.023940</td>\n",
       "      <td>0.116888</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>-0.081184</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.665234</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.910224</td>\n",
       "      <td>-0.979597</td>\n",
       "      <td>0.610582</td>\n",
       "      <td>0.515577</td>\n",
       "      <td>0.055653</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>0.367403</td>\n",
       "      <td>0.276059</td>\n",
       "      <td>0.247405</td>\n",
       "      <td>0.025235</td>\n",
       "      <td>0.048601</td>\n",
       "      <td>0.496631</td>\n",
       "      <td>-0.060994</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.507289</td>\n",
       "      <td>-1.468973</td>\n",
       "      <td>-0.208351</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>0.318739</td>\n",
       "      <td>-0.599155</td>\n",
       "      <td>0.271468</td>\n",
       "      <td>0.029258</td>\n",
       "      <td>0.281890</td>\n",
       "      <td>0.145417</td>\n",
       "      <td>0.155879</td>\n",
       "      <td>-0.050884</td>\n",
       "      <td>-0.074240</td>\n",
       "      <td>0.066675</td>\n",
       "      <td>-0.163159</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.676385</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>0.672490</td>\n",
       "      <td>-0.781445</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>-0.421630</td>\n",
       "      <td>0.204497</td>\n",
       "      <td>0.090873</td>\n",
       "      <td>-0.031931</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>-0.248873</td>\n",
       "      <td>-0.298813</td>\n",
       "      <td>-0.188266</td>\n",
       "      <td>0.556631</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  0.803234 -0.597979 -0.285577 -0.770143 -0.017667  0.023372 -0.063243   \n",
       "1  0.383741 -0.558693  0.664729  1.081237  1.002544 -0.000102  0.260944   \n",
       "2  0.665234  0.025918  0.910224 -0.979597  0.610582  0.515577  0.055653   \n",
       "3  0.507289 -1.468973 -0.208351  0.967490  0.318739 -0.599155  0.271468   \n",
       "4  0.676385  0.010505  0.672490 -0.781445 -0.002355 -0.421630  0.204497   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0 -0.451023 -0.984059 -0.048342 -0.116927  0.258324 -0.415056 -0.299239   \n",
       "1  0.398450 -0.258088  0.143168  0.352092  0.023940  0.116888  0.069941   \n",
       "2  0.029394  0.367403  0.276059  0.247405  0.025235  0.048601  0.496631   \n",
       "3  0.029258  0.281890  0.145417  0.155879 -0.050884 -0.074240  0.066675   \n",
       "4  0.090873 -0.031931  0.006785 -0.248873 -0.298813 -0.188266  0.556631   \n",
       "\n",
       "       PC15  Performance  \n",
       "0 -0.045746            3  \n",
       "1 -0.081184            3  \n",
       "2 -0.060994            3  \n",
       "3 -0.163159            3  \n",
       "4  0.750617            3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Leer dataset de features versionado con DVC ===\n",
    "# Este archivo debe ser la versiÃ³n data-v1.2-features (despuÃ©s de feature engineering)\n",
    "DATA_PATH = \"../data/processed/student_performance_features.csv\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“‚ PASO 3: Cargando dataset de features para entrenamiento\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Archivo: {DATA_PATH}\")\n",
    "print(\"ðŸ’¡ Este archivo estÃ¡ versionado con DVC (data-v1.2-features)\")\n",
    "print(\"ðŸ’¡ AsegÃºrate de tener la versiÃ³n correcta con: dvc pull\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"âœ… Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "print(f\"ðŸ“Š Features: {df.shape[1]-1} componentes PCA + 1 target (Performance)\")\n",
    "print(\"=\"*70)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f414d",
   "metadata": {},
   "source": [
    "## SeparaciÃ³n en Conjunto de entrenamiento y prueba -estratificado-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085e3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Performance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d2c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, matriz de caracteristicas\n",
    "X = df.drop(columns=[target_column])\n",
    "# y, vairable objetivo\n",
    "y = df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c583d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeparaciÃ³n en conjunto de entrenamient y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=13,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8eb09",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "El flujo bÃ¡sico de MLflow para la gestiÃ³n de experimentos de machine learning consta de cuatro pasos fundamentales. \n",
    "\n",
    "**1. DefiniciÃ³n del experimento:** Antes de iniciar cualquier entrenamiento, se debe crear o seleccionar un experimento en MLflow mediante `mlflow.create_experiment()` o `mlflow.set_experiment()` o `mlflow.get_experiment_by_name(experiment_name)`. Esto permite agrupar y organizar los diferentes intentos de entrenamiento bajo un mismo contexto, facilitando la trazabilidad y comparaciÃ³n de resultados. \n",
    "\n",
    "**2. EjecuciÃ³n de una corrida (run) dentro del experimento:** Cada entrenamiento de modelo se encapsula en una \"run\", iniciada con `mlflow.start_run()`. Una run representa una ejecuciÃ³n individual, donde se pueden registrar todos los artefactos y mÃ©tricas asociados. \n",
    "\n",
    "**3. Logging de parÃ¡metros, mÃ©tricas y artefactos:** Durante la run, se emplean funciones como `mlflow.log_params()`, `mlflow.log_metrics()` y `mlflow.log_artifact()` para guardar los hiperparÃ¡metros utilizados, las mÃ©tricas de desempeÃ±o obtenidas y cualquier archivo relevante (por ejemplo, el modelo entrenado o grÃ¡ficos de evaluaciÃ³n). Este registro estructurado permite auditar y reproducir los experimentos fÃ¡cilmente. \n",
    "\n",
    "**4. Registro del modelo:** Una vez identificado el mejor modelo, se utiliza `mlflow.register_model()` para almacenarlo en el Model Registry de MLflow. Esto habilita la gestiÃ³n de versiones, la transiciÃ³n entre estados (staging, production, archived) y el despliegue controlado del modelo, asegurando que el ciclo de vida del modelo estÃ© completamente documentado y gestionado. Este flujo garantiza la reproducibilidad, trazabilidad y gobernanza de los modelos desarrollados.\n",
    "\n",
    "\n",
    "Es por ello que se ha decidido diseÃ±ar la funciÃ³n `evaluate_and_log_model()`. esta funciÃ³n trata de los siguiente:\n",
    "\n",
    "Claro, aquÃ­ tienes una explicaciÃ³n paso a paso de lo que hace la funciÃ³n `evaluate_and_log_model`:\n",
    "\n",
    "1. **Recibe los argumentos**:  \n",
    "    - Nombre del modelo, instancia del modelo, datos de entrenamiento y prueba, parÃ¡metros, nombre del experimento MLflow y logger.\n",
    "\n",
    "2. **Busca o crea el experimento en MLflow**:  \n",
    "    - Si el experimento no existe, lo crea.  \n",
    "    - Si ya existe, lo reutiliza.  \n",
    "    - Informa por el logger quÃ© experimento se estÃ¡ usando.\n",
    "\n",
    "3. **Inicia una corrida (run) en MLflow**:  \n",
    "    - Cada entrenamiento se encapsula en una run para registrar resultados.\n",
    "\n",
    "4. **Loguea los parÃ¡metros del modelo**:  \n",
    "    - Si se pasan parÃ¡metros, los registra en MLflow y lo informa por el logger.\n",
    "\n",
    "5. **Entrena el modelo**:  \n",
    "    - Ajusta el modelo con los datos de entrenamiento (`fit`).  \n",
    "    - Informa por el logger que el entrenamiento terminÃ³.\n",
    "\n",
    "6. **Realiza predicciones**:  \n",
    "    - Predice sobre el conjunto de prueba.  \n",
    "    - Redondea las predicciones para obtener clases enteras.\n",
    "\n",
    "7. **Calcula mÃ©tricas**:  \n",
    "    - Calcula el RMSE (error cuadrÃ¡tico medio raÃ­z) entre las predicciones y los valores reales.  \n",
    "    - Calcula el QWK (Cohenâ€™s Kappa ponderado cuadrÃ¡tico) para evaluar la calidad de la clasificaciÃ³n ordinal.\n",
    "\n",
    "8. **Registra las mÃ©tricas en MLflow**:  \n",
    "    - Loguea RMSE y QWK en MLflow.  \n",
    "    - Informa por el logger los valores obtenidos.\n",
    "\n",
    "9. **Guarda el modelo en MLflow**:  \n",
    "    - Registra el modelo entrenado como artefacto en MLflow.  \n",
    "    - Informa por el logger que el modelo fue guardado.\n",
    "\n",
    "10. **Devuelve las mÃ©tricas**:  \n",
    "     - Retorna RMSE y QWK para su uso posterior.\n",
    "\n",
    "\n",
    "**MÃ©tricas utilizadas: RMSE y QWK**\n",
    "\n",
    "- **RMSE (Root Mean Squared Error):**  \n",
    "    El RMSE es una mÃ©trica que mide la diferencia promedio entre los valores predichos por el modelo y los valores reales, penalizando mÃ¡s fuertemente los errores grandes. Se calcula como la raÃ­z cuadrada de la media de los errores al cuadrado. En problemas de regresiÃ³n y clasificaciÃ³n ordinal, el RMSE permite cuantificar quÃ© tan cerca estÃ¡n las predicciones de los valores verdaderos, siendo Ãºtil para evaluar modelos que predicen valores continuos o clases ordenadas. Un RMSE bajo indica que el modelo realiza predicciones precisas.\n",
    "\n",
    "- **QWK (Quadratic Weighted Kappa):**  \n",
    "    El QWK es una mÃ©trica diseÃ±ada para evaluar la concordancia entre dos clasificadores (por ejemplo, las predicciones del modelo y las etiquetas reales) en problemas de clasificaciÃ³n ordinal. Considera no solo si la predicciÃ³n es correcta, sino tambiÃ©n cuÃ¡n lejos estÃ¡ la predicciÃ³n de la clase verdadera, penalizando mÃ¡s los errores grandes. El QWK toma valores entre -1 y 1, donde 1 indica perfecta concordancia, 0 indica concordancia aleatoria y valores negativos indican peor que aleatorio. Es especialmente relevante en contextos donde las clases tienen un orden natural, como en este caso.\n",
    "\n",
    "Estas mÃ©tricas permiten comparar objetivamente el desempeÃ±o de los modelos en la predicciÃ³n de la variable ordinal \"Performance\", asegurando que tanto la precisiÃ³n como el respeto por el orden de las categorÃ­as sean considerados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785920d8",
   "metadata": {},
   "source": [
    "## FunciÃ³n auxiliar para el logging con MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8006de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_log_model(\n",
    "    model_name,\n",
    "    model,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    params=None,\n",
    "    experiment_name=\"Default_Experiment\",\n",
    "    logger=None,\n",
    "    tracking_dir=\"../data/mlflow\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train model, log metrics, parameters, and model artifact to MLflow.\n",
    "    Automatically creates or reuses an MLflow experiment by name.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model/run.\n",
    "        model: Untrained model instance (e.g., sklearn model).\n",
    "        X_train, X_test, y_train, y_test: Training/testing data.\n",
    "        params (dict, optional): Model parameters to log.\n",
    "        experiment_name (str): MLflow experiment name.\n",
    "        logger (logging.Logger, optional): Logger for status messages.\n",
    "        tracking_dir (str): Local path to store MLflow tracking data.\n",
    "    \"\"\"\n",
    "    # --- Ensure MLflow uses the desired local folder ---\n",
    "    mlflow.set_tracking_uri(f\"file:{tracking_dir}\")\n",
    "    if logger:\n",
    "        logger.info(f\"MLflow tracking directory set to: {tracking_dir}\")\n",
    "\n",
    "    # --- Handle experiment setup ---\n",
    "    existing_experiment = mlflow.get_experiment_by_name(name=experiment_name)\n",
    "    if existing_experiment is None:\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            name=experiment_name,\n",
    "            tags={\"owner\": \"equipo36\", \"project\": \"student-performance-prediction\"}\n",
    "        )\n",
    "        if logger:\n",
    "            logger.info(f\"Created new MLflow experiment: '{experiment_name}' (ID: {experiment_id})\")\n",
    "    else:\n",
    "        experiment_id = existing_experiment.experiment_id\n",
    "        if logger:\n",
    "            logger.info(f\"Using existing MLflow experiment: '{experiment_name}' (ID: {experiment_id})\")\n",
    "\n",
    "    # --- Start MLflow run ---\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=model_name):\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "            if logger:\n",
    "                logger.info(f\"Logged parameters for {model_name}: {params}\")\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        if logger:\n",
    "            logger.info(f\"Model '{model_name}' training complete.\")\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_class = np.rint(y_pred).astype(int)\n",
    "\n",
    "        # Compute metrics\n",
    "        rmse = root_mean_squared_error(y_test, y_pred_class)\n",
    "        qwk = cohen_kappa_score(y_test, y_pred_class, weights=\"quadratic\")\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"quadratic_weighted_kappa\", qwk)\n",
    "        if logger:\n",
    "            logger.info(f\"Metrics logged â€” RMSE: {rmse:.4f}, QWK: {qwk:.4f}\")\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, artifact_path=\"model\", input_example=X_test.iloc[:5])\n",
    "        if logger:\n",
    "            logger.info(f\"Model '{model_name}' logged to MLflow under experiment '{experiment_name}'.\")\n",
    "\n",
    "        return rmse, qwk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a2c16",
   "metadata": {},
   "source": [
    "## MLFlow server\n",
    "\n",
    "MLflow server es una herramienta que permite gestionar y monitorizar experimentos de machine learning de forma centralizada. Su propÃ³sito principal es almacenar los resultados, parÃ¡metros, mÃ©tricas y modelos generados durante el ciclo de vida de los experimentos, facilitando la trazabilidad, comparaciÃ³n y reproducibilidad. Al ejecutar el servidor MLflow, se habilita una interfaz web donde los usuarios pueden visualizar y administrar todos los experimentos registrados en la plataforma.\n",
    "\n",
    "En la celda siguiente, podemos encontrar cÃ³digo que nos ayuda a levantar el server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0cf6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MLflow server started at http://127.0.0.1:8080\n"
     ]
    }
   ],
   "source": [
    "import subprocess, time, os, signal\n",
    "\n",
    "# Configuration\n",
    "MLFLOW_HOST = \"127.0.0.1\"\n",
    "MLFLOW_PORT = 8080\n",
    "\n",
    "# Start the MLflow server in background\n",
    "mlflow_process = subprocess.Popen(\n",
    "    [\n",
    "        \"mlflow\", \"server\",\n",
    "        \"--host\", MLFLOW_HOST,\n",
    "        \"--port\", str(MLFLOW_PORT),\n",
    "    ],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… MLflow server started at http://{MLFLOW_HOST}:{MLFLOW_PORT}\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066aaeb8",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146d5d9",
   "metadata": {},
   "source": [
    "### DefiniciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349064d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LightGBM params\n",
    "params_lgb = {\n",
    "    'objective': 'regression',    # or 'rmse' â€” continuous ordinal target\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 13\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model_lgb = lgb.LGBMRegressor(**params_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7970ca",
   "metadata": {},
   "source": [
    "### Entrenamiento y logging con mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f30ad62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:06 | INFO ] mlflow experiments -> MLflow tracking directory set to: ../data/mlflow\n",
      "[2025-10-12 18:05:06 | INFO ] mlflow experiments -> Created new MLflow experiment: 'mlflow-student-performance-experiment' (ID: 155893811526728657)\n",
      "[2025-10-12 18:05:06 | INFO ] mlflow experiments -> Logged parameters for LightGBM: {'objective': 'regression', 'metric': 'rmse', 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1, 'random_state': 13}\n",
      "[2025-10-12 18:05:08 | INFO ] mlflow experiments -> Model 'LightGBM' training complete.\n",
      "[2025-10-12 18:05:08 | INFO ] mlflow experiments -> Metrics logged â€” RMSE: 0.8819, QWK: 0.5097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/12 18:05:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\81083075\\Documents\\ML Projects\\MLOps\\equipo36mlops\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:30 | INFO ] mlflow experiments -> Model 'LightGBM' logged to MLflow under experiment 'mlflow-student-performance-experiment'.\n"
     ]
    }
   ],
   "source": [
    "lgb_rmse, lgb_qwk = evaluate_and_log_model(\n",
    "    experiment_name=\"mlflow-student-performance-experiment\",\n",
    "    model_name=\"LightGBM\",\n",
    "    model=model_lgb,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    params=params_lgb,\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03656430",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe8040",
   "metadata": {},
   "source": [
    "### DefiniciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "215b749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DefiniciÃ³n del modelo\n",
    "# NOTE: Usamos un diccionario para definir los hiperparÃ¡metros del modelo\n",
    "params_xgb = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'random_state': 13\n",
    "}\n",
    "# Instanciamos el modelo\n",
    "model_xgb = xgb.XGBRegressor(**params_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e1cb5",
   "metadata": {},
   "source": [
    "### Entrenamiento y loggeo con mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ff234f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:30 | INFO ] mlflow experiments -> MLflow tracking directory set to: ../data/mlflow\n",
      "[2025-10-12 18:05:30 | INFO ] mlflow experiments -> Using existing MLflow experiment: 'mlflow-student-performance-experiment' (ID: 155893811526728657)\n",
      "[2025-10-12 18:05:30 | INFO ] mlflow experiments -> Logged parameters for XGBoost: {'objective': 'reg:squarederror', 'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 6, 'random_state': 13}\n",
      "[2025-10-12 18:05:32 | INFO ] mlflow experiments -> Model 'XGBoost' training complete.\n",
      "[2025-10-12 18:05:32 | INFO ] mlflow experiments -> Metrics logged â€” RMSE: 0.8477, QWK: 0.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/12 18:05:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:37 | INFO ] mlflow experiments -> Model 'XGBoost' logged to MLflow under experiment 'mlflow-student-performance-experiment'.\n"
     ]
    }
   ],
   "source": [
    "xgb_rmse, xgb_qwk = evaluate_and_log_model(\n",
    "    experiment_name=\"mlflow-student-performance-experiment\",\n",
    "    model_name=\"XGBoost\",\n",
    "    model=model_xgb,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    params=params_xgb,\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3952e69",
   "metadata": {},
   "source": [
    "## CatBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9cfaf",
   "metadata": {},
   "source": [
    "### DefiniciÃ³n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e96fce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CatBoost parameters\n",
    "params_cat = {\n",
    "    'iterations': 300,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',   # Continuous target, respects ordering\n",
    "    'random_seed': 42,\n",
    "    'verbose': 0,\n",
    "    'od_type': 'Iter',         # Enable early stopping\n",
    "    'od_wait': 20\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model_cat = CatBoostRegressor(**params_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6880f745",
   "metadata": {},
   "source": [
    "### Entrenamiento y loggeo con mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f1e3206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:37 | INFO ] mlflow experiments -> MLflow tracking directory set to: ../data/mlflow\n",
      "[2025-10-12 18:05:37 | INFO ] mlflow experiments -> Using existing MLflow experiment: 'mlflow-student-performance-experiment' (ID: 155893811526728657)\n",
      "[2025-10-12 18:05:37 | INFO ] mlflow experiments -> Logged parameters for CatBoost: {'iterations': 300, 'learning_rate': 0.05, 'depth': 6, 'loss_function': 'RMSE', 'random_seed': 42, 'verbose': 0, 'od_type': 'Iter', 'od_wait': 20}\n",
      "[2025-10-12 18:05:38 | INFO ] mlflow experiments -> Model 'CatBoost' training complete.\n",
      "[2025-10-12 18:05:38 | INFO ] mlflow experiments -> Metrics logged â€” RMSE: 0.9108, QWK: 0.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/12 18:05:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-12 18:05:42 | INFO ] mlflow experiments -> Model 'CatBoost' logged to MLflow under experiment 'mlflow-student-performance-experiment'.\n"
     ]
    }
   ],
   "source": [
    "cat_rmse, cat_qwk = evaluate_and_log_model(\n",
    "    experiment_name=\"mlflow-student-performance-experiment\",\n",
    "    model_name=\"CatBoost\",\n",
    "    model=model_cat,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    params=params_cat,\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06008358",
   "metadata": {},
   "source": [
    "# Finalmente\n",
    "\n",
    "Detenemos el servidor de MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817aa384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'mlflow_process' in locals() and mlflow_process.poll() is None:\n",
    "#     os.kill(mlflow_process.pid, signal.SIGTERM)\n",
    "#     print(\"ðŸ›‘ MLflow server stopped.\")\n",
    "# else:\n",
    "#     print(\"MLflow server was not running or already stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78327756",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Versionar Experimentos MLflow con DVC\n",
    "\n",
    "Una vez que hayas terminado de entrenar y evaluar los modelos, es recomendable versionar los experimentos y artefactos de MLflow con DVC para tener un registro completo del pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Versionar directorio MLflow con DVC ===\n",
    "MLFLOW_PATH = \"../data/mlflow\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… PASO 3 COMPLETADO: Modelos entrenados y registrados en MLflow\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ðŸ“‚ Directorio MLflow: {MLFLOW_PATH}\")\n",
    "print(f\"ðŸ“Š Experimentos registrados: LightGBM, XGBoost, CatBoost\")\n",
    "print(f\"ðŸ“ˆ MÃ©tricas: RMSE y QWK (Quadratic Weighted Kappa)\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“¦ SIGUIENTE PASO: Versionar experimentos MLflow con DVC\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸš€ Ejecuta este comando en la terminal:\\n\")\n",
    "print(f\"bash add_to_dvc.sh {MLFLOW_PATH} models-v1.0-baseline 'Baseline models: LightGBM, XGBoost, CatBoost'\")\n",
    "print(\"\\nðŸ’¡ O si prefieres hacerlo manualmente:\")\n",
    "print(f\"dvc add {MLFLOW_PATH}\")\n",
    "print(f\"git add {MLFLOW_PATH}.dvc .gitignore\")\n",
    "print('git commit -m \"feat: version models - baseline models trained\"')\n",
    "print('git tag -a \"models-v1.0-baseline\" -m \"Baseline models: LightGBM, XGBoost, CatBoost\"')\n",
    "print(\"dvc push\")\n",
    "print(\"git push origin $(git rev-parse --abbrev-ref HEAD) --tags\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ Pipeline MLOps completo con versionado de datos y modelos!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ“Œ Resumen de versiones:\")\n",
    "print(\"  â€¢ data-v1.0-raw:      Dataset original sin procesar\")\n",
    "print(\"  â€¢ data-v1.1-cleaned:  Dataset despuÃ©s de EDA y limpieza\")\n",
    "print(\"  â€¢ data-v1.2-features: Dataset con features engineered (PCA)\")\n",
    "print(\"  â€¢ models-v1.0-baseline: Modelos baseline entrenados\")\n",
    "print(\"\\nðŸ’¡ Para recuperar cualquier versiÃ³n:\")\n",
    "print(\"  git checkout <tag-name>\")\n",
    "print(\"  dvc checkout\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e956e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
